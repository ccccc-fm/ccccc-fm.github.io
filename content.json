{"posts":[{"title":"Linux服务器之间挂载共享目录","text":"Linux现有比较成熟的解决方案有两种，一种是NFS远程挂载，另一种是Samba共享目录。下面使用NFS，即网络文件系统（Network File System）分布式文件系统协议 环境 服务端-A服务器 121.4.247.245 Centos 客户端-B服务器 1.12.221.166 Ubuntu 步骤服务端设置共享目录，客户端挂载目录 服务端-A服务器 安装NFS 由于NFS是依赖于RPC协议来进行的协议传输，所以，此时需同时安装，NFS 和 RPC 两个应用程序 1yum -y install nfs-utils rpcbind 设置共享目录 NFS的配置文件在/etc/exports，内容默认为空。配置格式为：目录位置 客户机地址(权限选项) 123vim /etc/exports//添加如下内容/sharetest 1.12.221.166(insecure,rw,no_root_squash,no_all_squash,sync) 其中，/sharetest是服务器端要共享出来的目录，1.12.221.166是客户端的ip，rw代表客户端可以对共享目录进行读写操作。 启动NFS服务12345678#启动rpc服务(stop关闭)systemctl start rpcbind#启动nfs服务(stop关闭)systemctl start nfs#查看rpc服务状态systemctl status rpcbind#查看nfs服务状态systemctl status nfs 查看当前机器已经发布的NFS共享目录1showmount -e 此时共享文件A服务器的配置已经完成，可直接在B服务器进行目录的挂载操作 客户端-B服务器 安装RPC服务1apt-get install rpcbind 挂载1mount -t nfs 121.4.247.245:/data/share /data/store df -h 查看挂载目录 开机自动挂载12vim /etc/fstab121.4.247.245:/sharetest /sharetest nfs defaults,_netdev 0 0 开机自动启动1systemctl enable rpcbind.service 注意：/etc/fstab是用来存放文件系统的静态信息的文件,当系统启动的时候，系统会自动地从这个文件读取信息，并且会自动将此文件中指定的文件系统挂载到指定的目录。如果挂载的格式不正确会导致服务器启动失败，需要进入救援者模式处理，谨慎操作fstab文件。linux之fstab文件详解:https://blog.csdn.net/qq_32907195/article/details/117512634 开机自动挂载可以写脚本开机自动执行，脚本中使用命令挂载 卸载共享目录在客户端服务器卸载 1umount -l /sharetest 卸载后未生效，文件依旧会同步~~~ 其他 如果NFS服务器端的防火墙没有关闭的话，共享目录在挂载的时候就会出现挂载失败，连接超时的问题（mount.nfs:Connection timed out） 服务器端exports的客户端配置选项要加上insecure参数，例如：/sharedata 192.168.10.109(insecure,rw)。 如果不加上insecure参数的话，在挂载共享目录时，可能会提示如下错误：mount.nfs:access denied by server while mounting。 共享文件夹最好设置权限 chmod -R 777 /sharetest","link":"/2022/11/15/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B9%8B%E9%97%B4%E6%8C%82%E8%BD%BD%E5%85%B1%E4%BA%AB%E7%9B%AE%E5%BD%95/"},{"title":"RocketMq入门","text":"介绍: MQ的用处 限流削峰 异步解耦 数据收集：收集业务日志、监控数据、用户行为 RocketMQ基础概念 消息(message): 生产和消费数据的最小单位，每条消息必须属于一个主题 主题(topic): 一类消息的集合，每个主题包含多个消息。一个生产者可以生产多个topic消息，一个消费者只能消费一个topic **标签(Tag)**：为消息设置的标签用于同一个topic下区分不同类型的消息 **队列(Queue)**：存储消息的物理实体，一个topic包含多个Queue，每个Queue中存放的就是该Topic的消息。一个topic中的queue也叫topic中消息的分区。一个queue只能被一个消费者消费 消息标识(MessageId/key): 消息的唯一标识，生产者发送消息会产生一个msgId，消费者接收消息会产生offsetMsgId，用户指定而定业务id叫key 架构 producer：生产消息 consumer：进行消息消费 负载均衡：一个topic中的queue会平均分配给消费者组中的消费者 容错：组中的一个消费者挂掉后，其他的消费者会平分该消费者的queue 消费者组只能消费一个topic的消息，不能同时消费多个topic的消息 一个消费者组中的消费者必须订阅完全相同的topic NameServer：broker和topic路由的注册中心，功能：broker管理、路由信息管理 broker：用于存储和转发消息 工作流程①:启动namerserver -&gt; ②:启动broker -&gt; ③:创建topic -&gt; ④:生产消息 -&gt; ⑤:消费消息1：namerserver因为rockermq的注册中心是无状态的，所以它的broker信息与路由信息需要broker主动发送给nameserver，所以先启动nameserver，关闭时先关闭broker2：创建topic发送消息前应该先创建topic也可以设置自动创建，手动创建topic有两种方式：集群模式和broker模式，区别在于集群模式创建的topic在每个broker中的读写队列数量都是一致的，而broker模式你需要在逐个选择broker进行创建topic，读写队列自然数量自然可以不同。手动创建topic的参数有四个：创建模式、读队列数量、写队列数量、perm。perm用于设置对当前创建Topic的操作权限：2表示只写，4表示只读，6表示读写。3：读写队列生产者将消息写入写队列，消费者从队列中读取消息。在物理上读写队列是同一个队列，一般情况读写队列数量是相同的。但broker模式创建topic时读写队列数量不同，这样是为了缩容。缩容：如现在读写队列数量都为16个，需要缩容为都是8个，且保证消息不丢失。可以先将写队列动态调整为8个，此时只有8个写队列在往里写消息，16个队列在消费消息，待停止写入消息的那8个队列的消息消费完了之后，将读队列的数量修改为8，即实现了缩容 工作原理生产消息 生产过程： Producer发送消息之前，会先向NameServer发出获取 消息Topic的路由信息 的请求 NameServer返回该Topic的 路由表 及 Broker列表 路由表是个map，key是topic名称，value是broker列表，列表中没有地址只有名称，produer通过路由表找到brokername,再从broker列表中找到broker地址 Producer根据代码中指定的Queue选择策略，从Queue列表中选出一个队列，用于后续存储消息 Queue选择算法：无序消息：轮询和最小投递延迟算法 Produer对消息做一些特殊处理，例如，消息本身超过4M，则会对其进行压缩 Producer向选择出的Queue所在的Broker发出RPC请求，将消息发送到选择出的Queue 轮询算法：默认选择的算法，保证消息在队列中均匀的消费消息1发送个队列1，消息2发送给队列2，以此类推。缺点：消息1发送后，生产者要等消息成功发送后再把消息2发送给队列2，不成功下次还是给队列1发送。这样一来可能造成消息在生产者的缓存队列中大量积压，影响性能。 最小投递延迟算法统计每个队列投递消息的延迟，选择最小的队列进行投递，缺点：可能造成一个队列中存放了大量消息，造成消费者消费者能力下降，消息在MQ中积压严重 消息的存储RocketMQ中的消息存储在本地文件系统中，这些相关文件默认在当前用户主目录下的store目录中。 indexFile除了通过通常的指定Topic进行消息消费外，RocketMQ还提供了根据key进行消息查询的功能。该查询是通过store目录中的index子目录中的indexFile进行索引实现的快速查询。当然，这个indexFile中的索引数据是在 包含了key的消息 被发送到Broker时写入的。如果消息中没有包含key，则不会写入。 消费消息 获取消息 **拉取式消费(pull)**：Consumer主动从Broker中拉取消息。实时性弱 拉取消息的时间是用户指定的，拉取时间需要注意平衡,RocketMq默认使用拉取式消费，拉取间隔15秒 推送式消费(push): broker收到消息后主动推送给consumer，实时性高，耗费资源 consumer向其关联的queue注册了监听器，这需要长连接，所以耗费资源(与每个broker建立长连接) **长轮询(long polling)**：消费者定时去broker中获取消息，如果没获取到消息，保持连接一段时间，比如30s，30s内没有消息，则断开连接，30s内有消息，则消费消息且再等30s。中和了pull和push的利弊。 消费消息 广播消费消费者组中的每个消费者都接收topic全量的消息，各自进行消费，一条消息被消费n次，消费进度保存在消费者中 集群消费消费者组中的消费者平摊topic所有的消息，一条消息被消费一次，进度需要共享，所以消费进度存放在broker中 Rebalance机制Relablance机制指当消费者组中的消费者数量发生变化（宕机、新增）时、消费者所订阅的Topic中的Queue数量发生变化时，将Topic中的多个Queue重新分配给消费者的机制。Reblance机制的前提是集群消费。在进行Reblance时，会导致消费暂停，重新分配Queue后继续消费，这可能会导致消息重复或者暂停时间过长导致消息积压。优点是可以提升消费能力 Queue分配算法 平均分配：先根据Queue的数量和消费者的数量计算每个消费者分配的Queue数量，如不能平均分配，则将多于的Queue逐个分配个消费者。 环形平均分配：消费者逐个从Queue队列中领取，与平均分配不同的是，平均分配的Queue是连续的，比如Consumer1会拿到0、1、3的Queue，而环形会拿到0、3、6的Queue 一致hash策略：将consumer的hash值作为Node节点存放到hash环上，然后将queue的hash值也放到hash环上，通过 顺时针 方向，距离queue最近的那个consumer就是该queue要分配的consumer。（分配不均） 同机房分配：根据queue的部署机房位置和consumer的位置，过滤出当前consumer相同机房的queue。然后按照平均分配策略或环形平均策略对同机房queue进行分配 订阅关系一致性错误的订阅关系会导致消费逻辑混乱、丢失消息正确的订阅关系：多个消费者组订阅了多个Topic，并且每个消费者组里的多个消费者实例的订阅关系保持了一致。错误的订阅关系： 一个消费者组中的消费者订阅了不同的Topic 一个消费者组中的消费者订阅了相同的Topic，不同的Tag 一个消费者组中的消费者订阅了不同数量的消费者 消息幂等某个操作执行多次和执行一次对系统的影响都是一样的，则为幂等操作。读操作一般都是幂等的，幂等性一般讨论的都是写操作。对于RocketMq来说，如果出现消息重复，就可能会重复消费影响业务。 RocketMq可能出现的消息重复场景 producer将消息发送给broker，broker持久化消息后因为网络原因没有给produce发送接收到消息的响应，produce会判断为消息发送失败，会重复发送失败的消息，并不会重新生成msgId。 consumer接收到消息后没有给broker成功的响应，broker会重复给consumer发送消息 Rebalance时导致消息重复 通用的幂等性解决方案通常通过幂等令牌实现幂等性操作，如支付操作：producer发送消息时带上幂等令牌，支付中可能是订单号。consumer处理消息时进行三步处理： 检查缓存中有无与令牌相同的key，如存在则认定为重复操作，如不存在则进行下一步 检查数据库中有无该令牌为索引的数据，如存在则认定为重复操作，不存在则进行下一步 进行到这一步就已经认定为未重复，进行业务操作，然后将令牌存入缓存、数据库 为什么缓存中判重后还要在数据库中再次判重？因为为了性能，缓存中一般存的都是有有效期的，存在key过期而不存在的情况 在RocketMq中producer可以在发送消息时将幂等令牌设置为消息的key message.setKey(&quot;XXXXX&quot;) message的标识有三个：msgId(producer生成)、offsetMsgId(broker生成)、key(用户指定的业务唯一标识) 代码举例 依赖，以下案例使用rocketmq-client依赖举例 &lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.9.4&lt;/version&gt; &lt;/dependency&gt; 普通消息消息根据发送类型分为： 同步发送：producer发送一条消息后，收到MQ的响应后发送下一条消息，可靠性高效率低 异步发送：无需等待响应(但会接收响应)，直接发送下一条，可靠性一般、效率一般 单向发送：不接收响应，可靠性差，效率高 producer发送消息 //失败重试次数、默认2次 producer.setRetryTimesWhenSendFailed(3); //发送超时时间，默认3秒，单向消息设置超时时间貌似会报超时错误 //超时错误：sendDefaultImpl call timeout producer.setSendMsgTimeout(5000); //指定新创建的Topic的Queue数量为2，默认为4 producer.setDefaultTopicQueueNums(2); /** * 发送同步消息 * @throws Exception */ @Test public void syncSend() throws Exception { DefaultMQProducer producer = new DefaultMQProducer(&quot;myGroup&quot;); producer.setNamesrvAddr(IP_PORT); producer.start(); byte[] body = &quot;123&quot;.getBytes(); Message msg = new Message(&quot;testSyncTopic&quot;, &quot;test&quot;, body); SendResult send = producer.send(msg); producer.shutdown(); } /** * 发送异步消息 * @throws Exception */ @Test public void asyncSend() throws Exception { DefaultMQProducer producer = new DefaultMQProducer(&quot;myAsyncGroup&quot;); producer.setNamesrvAddr(IP_PORT); producer.start(); byte[] body = &quot;test&quot;.getBytes(); Message msg = new Message(&quot;testSyncTopic&quot;, &quot;test&quot;, body); producer.send(msg, new SendCallback() { @Override public void onSuccess(SendResult sendResult) { //发送成功的回调，sendResult为返回结果 System.out.println(sendResult); } @Override public void onException(Throwable throwable) { //发送失败的异常信息 System.out.println(throwable.getMessage()); } }); //异步发送，如果直接关闭生产者，可能消息还没发完 Thread.sleep(3000); producer.shutdown(); } /** * 发送单单向消息 * @throws Exception */ @Test public void oneWaySend() throws Exception { DefaultMQProducer producer = new DefaultMQProducer(&quot;myAsyncGroup&quot;); producer.setNamesrvAddr(IP_PORT); producer.start(); byte[] body = &quot;test&quot;.getBytes(); Message msg = new Message(&quot;testOneWayTopic&quot;, &quot;test&quot;, body); producer.sendOneway(msg); producer.shutdown(); } consumer接收消息 // 指定采用“广播模式”进行消费，默认为“集群模式” consumer.setMessageModel(MessageModel.BROADCASTING); /** * 接收消息 * @throws Exception */ @Test public void consumer() throws Exception { while (true){ System.out.println(&quot;into&quot;); DefaultMQPushConsumer consumer =new DefaultMQPushConsumer(&quot;myConsumerGroup&quot;); consumer.setNamesrvAddr(IP_PORT); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(&quot;testSyncTopic&quot;,&quot;*&quot;); // consumer.subscribe(&quot;testOneWayTopic&quot;,&quot;*&quot;); consumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext context) { list.forEach(msg-&gt;{ System.out.println(new String(msg.getBody())); }); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); consumer.start(); Thread.sleep(5000); } } 顺序消息顺序消息指的是，严格按照消息的 发送顺序 进行 消费 的消息(FIFO)。 普通消息为什么不是顺序的？producer生产消息后会根据算法(轮询、最小投递)将消息投递到不同的Queue中，每个Queue中虽然是先进先出的，但是不同Queue中的消费速度可不一样，将消息投递到不同的Queue中当然不是顺序的。所以要保证消息的顺序，就要保证消息在同一个Queue中，比如一个订单的三条消息：创建、付款、完成。三条都在一个Queue中。注意:一个Queue只能被一个消费者消费，所以放在一个Queue中就是顺序的 如何保证消息在一个Queue中？ producer设置Topic下的Queue数量为1.称之为全局顺序 producer通过Queue选择算法指定消息投递到哪个Queue中，订单场景中就是设置每个订单的三个消息都能进到同一个Queue中，称之为部分顺序 全局顺序与部分顺序的代码是相同的。Queue选择算法就是通过计算得出消息投递的Queue索引，相同订单的三个消息计算出的索引是相同的，就会被投递到同一队列。常用的方法就是Hash取模，用订单ID%队列数量得到Queue索引 如何完成一次顺序消息的发送、消费？ 保证消息在同一个Queue中 同步发送，顺序消息只能用同步发送(虽然提供了异步方法，但不能保证有序) consumer使用有序消费模式进行消费MessageListenerOrderly 代码注意：订单id是通过send方法的第三个参数传递进去的、消费者中用顺序监听器最后观察消费者的输出，同一个订单的消息都在同一个Queue中 /** * 发送顺序消息 * @throws Exception */ @Test public void syncSend() throws Exception { DefaultMQProducer producer = new DefaultMQProducer(&quot;myGroup&quot;); producer.setNamesrvAddr(IP_PORT); producer.start(); Integer[] orderIds =new Integer[]{111,222,333}; for (Integer i = 0; i &lt; 13; i++) { //有4条消息的orderId是111，这4条消息计算Queue索引时都是相同的，就会被投递到相同的队列中 int index = i%3; Integer orderId = orderIds[index]; byte[] body = orderId.toString().concat(&quot;-&quot;).concat(i.toString()).getBytes(); Message msg = new Message(&quot;testOrderlyTopic&quot;, &quot;test&quot;, body); //传递三个参数：message,选择器,选择器Key 这个选择器key就是内部类方法select()的参数 SendResult sendResult = producer.send(msg, new MessageQueueSelector() { @Override public MessageQueue select(List&lt;MessageQueue&gt; list, Message message, Object key) { Integer orderId = (Integer) key; //计算投递的Queue的索引 int queueIndex = orderId % list.size(); return list.get(queueIndex); } },orderId); } producer.shutdown(); } /** * 接收消息 * @throws Exception */ @Test public void consumer() throws Exception { while (true){ System.out.println(&quot;into&quot;); DefaultMQPushConsumer consumer =new DefaultMQPushConsumer(&quot;myConsumerGroup&quot;); consumer.setNamesrvAddr(IP_PORT); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(&quot;testOrderlyTopic&quot;,&quot;*&quot;); consumer.registerMessageListener(new MessageListenerOrderly() { @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeOrderlyContext consumeOrderlyContext) { list.forEach(entity-&gt;{ int queueId = entity.getQueueId(); String bodyString = new String(entity.getBody()); System.out.println(queueId+&quot;----&quot;+bodyString); }); return ConsumeOrderlyStatus.SUCCESS; } }); consumer.start(); Thread.sleep(500); } } 延时消息延时消息顾名思义就是延迟发送消息，典型的应用场景就是一段时间内未支付，则结束订单。开启订单后，发送一条延时30分钟的消息，30分钟后消费者收到消息，拿到订单号，检查该订单是否已经支付，如果未支付则结束订单，将商品放回商品库。 Rocketmq中不能设置延时时间，只能设置延时等级，不同的延时等级对应不同的延时时间，延时等级从1开始。延时等级定义在RocketMQ服务端的 MessageStoreConfig 类中。如果需要自定义的延时等级，可以通过在broker加载的配置中新增如下配置（例如下面增加了1天这个等级1d）。配置文件在RocketMQ安装目录下的conf目录中。 messageDelayLevel = 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 1d 实现原理producer将消息发送到broker后，broker会将消息先放到commitlog中，然后再分发到对应的queue，在分发之前会判断消息有无延时，如没有延时，则正常发送，如果有延时等级将会修改消息的topic为SCHEDULE_TOPIC_XXXX，并将消息发送到该topic的queue下。broker中有个延迟消息服务类ScheuleMessageService，会消费该主题下的消息，该服务类在到达延时时间后将消息的延时等级设为0，重新投递到原topic中。 代码举例比较简单 msg.setDelayTimeLevel(3); 事务消息分布式事务概念 什么是一致性？在分布式系统中，一致性（Consistency）是指多副本（Replications）问题中的数据一致性一致性的种类：事务一致性、数据一致性数据一致性的种类： 弱一致性：如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性 强一致性：同步复制数据，所有节点中的数据是一样的 最终一致性：就是在一段时间后，节点间的数据会最终达到一致状态，是弱一致性的一种 顺序一致性：任何一次读都能读到某个数据的最近一次写的数据 什么是XA协议？一套分布式事务标准，使用了两阶段提交来保证分布式事务的完整性XA模式中有三个重要组件：TC、TM、RM。 TC: Transaction Coordinator，事务协调者。维护全局和分支事务的状态，驱动全局事务提交或回滚。RocketMQ中Broker充当着TC。 TM：Transaction Manager，事务管理器。定义全局事务的范围：开始全局事务、提交或回滚全局事务。它实际是全局事务的发起者。RocketMQ中事务消息的Producer充当着TM。 RM：Resource Manager，资源管理器。管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。RocketMQ中事务消息的Producer及Broker均是RM。 XA模型 TM向TC发起指令，开启一个全局事务。 根据业务要求，各个RM会逐个向TC注册分支事务，然后TC会逐个向RM发出预执行指令。 各个RM在接收到指令后会在进行本地事务预执行。 RM将预执行结果Report给TC。当然，这个结果可能是成功，也可能是失败 TC在接收到各个RM的Report后会将汇总结果上报给TM，根据汇总结果TM会向TC发出确认指令 若所有结果都是成功响应，则向TC发送Global Commit指令。 只要有结果是失败响应，则向TC发送Global Rollback指令 TC在接收到指令后再次向RM发送确认指令 RocketMq中的概念 半事务消息：咱不能投送的消息，producer已经将消息发送到了broker但是事务状态没有确定，此时该消息对于consumer不可见 本地事务状态：producer回调操作执行的结果，TC会将本地事务状态发送给TM，TM根据本地事务状态确定全局事务状态 消息回查：即重新查询本地事务的执行状态，本地事务返回的结果如果是不确定，则会进行回查，重新返回本地事务状态 RocketMq中的事务消息A银行给B银行转账，分为4个步骤① A向B发送存款增加一万元的消息② A扣款一万元③ B收到消息，消费消息④ B增加存款一万元 Rocketmq只能做到步骤一和步骤二具有原子性，要想四个步骤成为一个操作，需要人工干预，见本节末。 如何保证步骤一和步骤二是一个原子操作，RocketMq的操作流程如下： Producer向Broker端发送Half Message(半事务消息)； broker给producer响应Half Message发送成功 producer收到消息发送成功的ACK，去执行本地事务（扣款操作） 本地事务执行完毕，返回本地事务状态：成功、失败、未知。broker根据本地事务状态执行commit或rollback成功(commit)：消息真正发送给consumer失败(rollback): 事务失败，消息不会发送给consumer，一段时间后清除消息未知(unknow): 状态不确定，进行消息回查，重新确认消息状态（正常的事务消息到这一步就已经结束） 如果本地事务执行超时时，broker会主动发起消息回查 producer进行消息回查，返回本地事务状态 broker根据本地事务状态执行commit或rollback 其中消息回查的结果如果还是unknow，则会继续回查，直到达到配置的最大回查次数，达到次数就报错最大回查次数、回查间隔时间等都是可以配置的 代码举例 定义事务监听器，定义本地事务和消息回查 /** * 事务监听器，本地事务和消息回查都在其中 */ class MyMqTransactionListener implements TransactionListener { /** * 本地事务 * @param message 消息 * @param args producer发送事务消息时传递的参数，用于执行本地事务时使用。不用就不传。此处的值应为123 * @return 返回本地事务状态：LocalTransactionState 有三种状态 */ @Override public LocalTransactionState executeLocalTransaction(Message message, Object args) { System.out.println(&quot;执行本地事务，A扣款操作~~~~&quot;); //返回执行成功，执行成功后broker会把消息发送给consumer //return LocalTransactionState.COMMIT_MESSAGE; //返回执行失败，失败后broker不会把消息发送给consumer //return LocalTransactionState.ROLLBACK_MESSAGE; //返回执行未知：去执行消息回查 return LocalTransactionState.UNKNOW; } /** * 消息回查 * @param messageExt 消息 * @return 返回本地事务状态，与执行本地事务的返回效果相同 */ @Override public LocalTransactionState checkLocalTransaction(MessageExt messageExt) { System.out.println(&quot;执行消息回查&quot;); return LocalTransactionState.COMMIT_MESSAGE; } } 发送消息注意：生产者的类型不再是DefaultMQProducer了、发送方法使用事务发送方法，可以使用业务参数消费者正常使用就行 /** * 发送事务消息 * @throws Exception */ @Test public void sendTransactionMsg() throws Exception { //定义事务生产者而不是默认的生产者 TransactionMQProducer producer = new TransactionMQProducer(&quot;myGroup1&quot;); producer.setNamesrvAddr(IP_PORT); //1: 定义一个线程池给producer去处理本地事务、消息回查 /** * @param corePoolSize 线程池核心线程数 * @param maximumPoolSize 线程池中最多线程数 * @param keepAliveTime 线程池中空闲线程的存活时间 * @param unit 时间单位 * @param workQueue 临时存放任务的队列，其参数就是队列的长度 * @param threadFactory 线程工厂 */ ThreadPoolExecutor executor = new ThreadPoolExecutor( 10, 50, 10L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(20), (Runnable r) -&gt; new Thread(&quot;Order Transaction Massage Thread&quot;)); producer.setExecutorService(executor); //2: 设置事务监听器，监听器中执行本地事务与消息回查，需要自己定义 producer.setTransactionListener(new MyMqTransactionListener()); //3：发送事务消息 producer.start(); Message msg = new Message(&quot;transactionTopic&quot;, &quot;test&quot;, &quot;hello&quot;.getBytes()); TransactionSendResult result = producer.sendMessageInTransaction(msg, &quot;123&quot;); System.out.println(&quot;发送结果：&quot;+result); producer.shutdown(); } 总结 RocketMq不能发送延时消息、批量消息 以上操作只保证了消息发送是原子的，那消息消费要怎么办？ 因为消费端RocketMQ有重试机制，如果不是代码问题一般重试几次就能成功，这里我们要保证消息消费的幂等性，即多次消费同一个消息对系统的状态没有影响，或者说不会影响最终正确的结果。比如上面的案例中，发生了重复消费，可能就会重复调用多次扣款的接口，我们要保证对同一个消息多次调用和一次调用的最终结果是一致的，而不是调用几次接口就扣款几次。 如果消费者一直执行失败，几乎可以断定就是代码有问题所以才引起的异常。如果多次失败并重试达到一定次数之后，可以先将该异常记录下来，通常是记录到数据库中，后续由人工处理，通过这样来让事务达到最终的一致性。 因此RocketMQ的事务消息不是强一致性的，而是保证最终一致性，并且可能需要人工介入。 目前，生产级别采用的各种分布式事务解决方案也几乎都是最终一致性的。试想一下，如果要保证强一致性的，即必须实时的保证数据的一致性，那么一定需要同步阻塞，此时将会阻塞大量的服务，降低消息分布式系统的可用性和并发度，这是更加不可容忍的。实际上也有强一致性的分布式事务方案，比如基于数据库的2PC实现，但是几乎很少使用，或者说，建议小公司谨慎使用分布式事务，能不用就不用。 与最终一致性对应的业务是，通常在客户进行操作之后，不会立即返回客户成功的信号，而是返回一个“业务正在办理中，成功了会通知你”、“钱款两小时内到账”等友好的延时提醒。 参考：https://blog.csdn.net/weixin_43767015/article/details/121308018 关于事务回查在demo中本地事务返回UNKNOW并没有触发事务回查，感觉官方并不推荐使用事务回查。且即便是本地事务返回UNKNOW也不会立即回查，而是固定的时间后再去回查，而demo中producer发送完消息就关闭了。 事务回查的触发条件，4.X版本的官方文档是这样描述的： 在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 5.X的官方文档是这样描述的： 在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 源码中也并没有对UNKNOW类型直接做处理（可能有定时器） if (localTransactionStatLocalTransactionState.COMMIT_MESSAGE) { log.info(&quot;executeLocalTransactionBranch return localTransactionState); log.info(msg.toString()); } 批量消息 概念批量发送消息需要注意的点： 批量发送的消息必须具有相同的Topic 批量发送的消息必须具有相同的刷盘策略 批量发送的消息不能是延时消息与事务消息 一批发送的消息总大小不能超过4MB字节 生产者批量发送消息不能超过4M，所以通常需要定义一个分割器确保不会超过4M，如果需要修改最大发送长度，需要在配置文件和代码中都进行设置和修改 消费者有两个属性：拉取消息的数量(pullBatchSize)、批量消费消息的数量(consumeMessageBatchMaxSize)。批量消费消息的时候是批量成功或批量失败的，一条失败则全部失败，所以要适当设置批量消费的数量。 另外，批量拉取和消费的数量并不一定和指定的数量一致，受网络影响，并不是一定会拉取到、消费到指定数量的消息 代码举例定义分割器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class MessageListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; { private final int SIZE_LIMIT = 4 * 1024 * 1024; // 存放所有要发送的消息 private final List&lt;Message&gt; messages; // 要进行批量发送消息的小集合起始索引 private int currIndex; public MessageListSplitter(List&lt;Message&gt; messages) { this.messages = messages; } @Override public boolean hasNext() { // 判断当前开始遍历的消息索引要小于消息总数 return currIndex &lt; messages.size(); } @Override public List&lt;Message&gt; next() { int nextIndex = currIndex; // 记录当前要发送的这一小批次消息列表的大小 int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) { // 获取当前遍历的消息 Message currentMsg = messages.get(nextIndex); int currentMsgSize = computeMsgSize(currentMsg); // 判断当前消息本身是否大于4M if (currentMsgSize &gt; SIZE_LIMIT) { if (nextIndex - currIndex == 0) { nextIndex++; } break; } if (currentMsgSize + totalSize &gt; SIZE_LIMIT) { break; } else { totalSize += currentMsgSize; } } // end-for // 获取当前messages列表的子集合[currIndex, nextIndex) List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); // 下次遍历的开始索引 currIndex = nextIndex; return subList; } /** * 计算单个消息的长度 * * @param message * @return */ private int computeMsgSize(Message message) { int size = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) { size += entry.getKey().length() + entry.getValue().length(); } size = size + 20; return size; }} 生产者消费者12345678910111213141516171819202122@SpringBootTestpublic class BatchMsgProducer { public static final String IP_PORT = &quot;121.4.247.245:9876&quot;; @Test public void sendBatchMessage() throws Exception { ... List&lt;Message&gt; messageList = new ArrayList&lt;&gt;(); ... MessageListSplitter splitter = new MessageListSplitter(messageList); while (splitter.hasNext()) { List&lt;Message&gt; msgs = splitter.next(); producer.send(msgs); } producer.shutdown(); }//消费者不一致的地方只有consumer.setConsumeMessageBatchMaxSize(25);consumer.setPullBatchSize(40);} 消息过滤消费者可以对消息进行过滤，有两种方式：Tag过滤、sql过滤 Tag过滤：选择订阅哪些tag，上文中订阅的都是全部，还可以这样写1consumer.subscribe(&quot;TOPIC&quot;, &quot;TAGA || TAGB || TAGC&quot;); Sql过滤：使用表达式进行更高级的过滤支持的表达式： 支持的常量类型：数值：比如：123，3.1415字符：必须用单引号包裹起来，比如：’abc’布尔：TRUE 或 FALSENULL：特殊的常量，表示空 支持的运算符有：数值比较：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=字符比较：=，&lt;&gt;，IN逻辑运算 ：AND，OR，NOTNULL判断：IS NULL 或者 IS NOT NULL 默认情况下Broker没有开启消息的SQL过滤功能，需要在Broker加载的配置文件中添加如下属性，以开启该功能： 1enablePropertyFilter = true 使用Sql过滤： 生产者添加属性1msg.putUserProperty(&quot;age&quot;, i + &quot;&quot;); 消费者过滤1consumer.subscribe(&quot;myTopic&quot;, MessageSelector.bySql(&quot;age between 0 and 6&quot;)) 消息发送重试消息发送的重试需要注意以下几点： 从发送消息的方式来讲，同步和异步会重试，单向不会。 从消息的类型来讲，普通消息有重试机制，顺序消息没有 消息发送重试机制会尽可能的保证发送成功，但可能会造成重复消费，所以消费者要做好幂等性处理 消息发送重试有三种策略可选择：同步发送失败策略、异步发送失败策略、消息刷盘失败策略 同步发送失败策略同步消息发送失败，在重试时会尽量选择其他broker发送，如果只有一个broker，也会尽量选择其他Queue。这就是失败隔离功能。 异步发送失败策略异步重试不会选择其他broker，仅在同一个broker上做重试，所以该策略无法保证消息不丢 消息刷盘失败策略消息刷盘超时（Master或Slave）或slave不可用（slave在做数据同步时向master返回状态不是SEND_OK）时，默认是不会将消息尝试发送到其他Broker的。不过，对于重要消息可以通过在Broker的配置文件设置retryAnotherBrokerWhenNotStoreOK属性为true来开启。 消息消费重试 对于顺序消息，当Consumer消费消息失败后，为了保证消息的顺序性，其会自动不断地进行消息重试，直到消费成功。消费重试默认间隔时间为1000毫秒。重试期间应用会出现消息消费被阻塞的情况 对于无序消息（普通消息、延时消息、事务消息），当Consumer消费消息失败时，可以通过设置返回状态达到消息重试的效果。不过需要注意，无序消息的重试只对集群消费方式生效，广播消费方式不提供失败重试特性。即对于广播消费，消费失败后，失败消息不再重试，继续消费后续消息。 对于 无序消息集群消费 下的重试消费，每条消息默认最多重试16次，但每次重试的间隔时间是不同的，会逐渐变长 重试队列：对于需要重试消费的消息，并不是Consumer在等待了指定时长后再次去拉取原来的消息进行消费，而是将这些需要重试消费的消息放入到了一个特殊Topic的队列中，而后进行再次消费的。这个特殊的队列就是重试队列 死信队列当一条消息初次消费失败，消息队列会自动进行消费重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。这个队列就是死信队列（Dead-Letter Queue，DLQ），而其中的消息则称为死信消息（Dead-Letter Message，DLM） 死信队列的特征 死信队列中的消息不会再被消费者正常消费，即DLQ对于消费者是不可见的 死信存储有效期与正常消息相同，均为 3 天（commitlog文件的过期时间），3 天后会被自动删除 死信队列就是一个特殊的Topic，名称为 %DLQ%consumerGroup@consumerGroup ，即每个消费者组都有一个死信队列 如果一个消费者组未产生死信消息，则不会为其创建相应的死信队列","link":"/2022/11/13/RocketMq%E5%85%A5%E9%97%A8/"},{"title":"基于Socket实现简易RPC调用","text":"什么是RPC调用?远程过程调用(Remote Procedure Call)，是一种远程调用的通信模型。简易的流程就是调用者将请求参数序列化，然后使用某种通信协议(http tcp udp等)将信息传递给被调用者，被调用者再将信息序列化后返回给调用者。 本文实现简单的RPC调用，主要模块如下： rpc-api 存放公共的接口以及通信的参数 rpc-client 调用者 rpc-server 被调用者 主要流程： client使用动态代理将参数序列化后通过Socket传递给server server通过反射执行实现类的方法，将返回值返回给client rpc-apirpc-client和rpc-server都依赖rpc-api 远程调用需要的参数封装类，该类必须序列化 12345678910public class ProxyParam implements Serializable { private static final long serialVersionUID = 1L; private String className; //类名 private String methodName; //方法名 private Class&lt;?&gt;[] paramTypes; //方法参数类型 private Object[] params; //参数} 接口，计算两数相加之和 123public interface IRpcComputeService { Integer computeAdd(Integer argFirst, Integer argSecond);} rpc-server接口实现类，真正的方法实现 1234567public class RpcComputeServiceImpl implements IRpcComputeService { @Override public Integer computeAdd(Integer argFirst, Integer argSecond) { return argFirst + argSecond; }} 主方法，创建socket监听8080端口，监听到请求后做处理，为了高效，使用线程池异步做处理，做到非阻塞 123456789101112131415161718192021public class RpcServer { public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); IRpcComputeService service =new RpcComputeServiceImpl(); ServerSocket serverSocket = null; try { serverSocket = new ServerSocket(8080); while (true) { Socket socket = serverSocket.accept(); System.out.println(&quot;server: 收到消息-&quot;+socket); executorService.execute(new Process(socket,service)); Thread.sleep(100); } } catch (Exception e) { throw new RuntimeException(e); } }} 定义Runnable，在这里处理接收到的socket 12345678910111213141516171819202122232425262728293031323334353637383940class Process implements Runnable { private Socket socket; private Object service; public Process(Socket socket,Object service) { this.socket = socket; this.service = service; } @Override public void run() { ObjectInputStream inputStream = null; ObjectOutputStream outputStream = null; Integer result = null; try { inputStream = new ObjectInputStream(socket.getInputStream()); outputStream = new ObjectOutputStream(socket.getOutputStream()); //读取socket发来的信息 ProxyParam param = (ProxyParam) inputStream.readObject(); //执行实现方法 result = invokeByParam(param); //将结果返回 outputStream.writeObject(result); outputStream.flush(); } catch (Exception e) { throw new RuntimeException(e); } } public Integer invokeByParam(ProxyParam proxyParam) throws Exception { String className = proxyParam.getClassName(); Class&lt;?&gt; clazz = Class.forName(className); Method method = clazz.getMethod(proxyParam.getMethodName(), proxyParam.getParamTypes()); Object result = method.invoke(service, proxyParam.getParams()); return (Integer)result; }} rpc-client主方法，通过动态代理实例化接口，调用接口方法 123456789101112public class RpcComputeClient { private static final String host = &quot;localhost&quot;; private static final Integer port = 8080; public static void main(String[] args) { IRpcComputeService computeProxy = RpcProxy.create(IRpcComputeService.class,host,port); Object result = computeProxy.computeAdd(85456, 345); System.out.println(&quot;client: result=&quot; + result); }} 动态代理，在这里发送socket请求 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class RpcProxy { private static String host; private static int port; public static &lt;T&gt; T create(Class&lt;?&gt; clazz,String remoteHost,Integer remotePort) { host = remoteHost; port=remotePort; // 返回这个实例 方便客户端使用 MethodProxy proxy = new MethodProxy(clazz); T result = (T) Proxy.newProxyInstance(clazz.getClassLoader(), new Class[]{clazz}, proxy); return result; } private static class MethodProxy&lt;T&gt; implements InvocationHandler { private T target; public MethodProxy(T target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object result = null; if (Object.class.equals(method.getDeclaringClass())) { //传进来的是实现类，则直接调用 result = method.invoke(target, args); } else { //传进来的是接口，则远程获取其他服务上的实现类，获取结果 ProxyParam param = new ProxyParam(); param.setMethodName(method.getName()); param.setClassName(method.getDeclaringClass().getName()); param.setParamTypes(method.getParameterTypes()); param.setParams(args); result = remoteInvoke(param); } return result; } private Object remoteInvoke(ProxyParam proxyParam) throws IOException { Socket socket = null; ObjectOutputStream outputStream = null; ObjectInputStream inputStream = null; Object result = null; try { socket = new Socket(host, port); //发送信息 outputStream = new ObjectOutputStream(socket.getOutputStream()); outputStream.writeObject(proxyParam); outputStream.flush(); //接收信息 inputStream = new ObjectInputStream(socket.getInputStream()); result = inputStream.readObject(); } catch (Exception e) { throw new RuntimeException(e); }finally { if(outputStream!=null){ outputStream.close(); } if(inputStream!=null){ inputStream.close(); } } return result; } }} Java动态代理举例接口 123public interface IPersonService { String getName(String UserId);} 实现类 12345public class PersonServiceImpl implements IPersonService{ public String getName(String userId){ return &quot;张三&quot;; }} 通过动态代理去调用实现类 12345678910111213141516public class main { public static void main(String[] args) { PersonServiceImpl personService = new PersonServiceImpl(); MyInvocationHandler myInvocationHandler = new MyInvocationHandler&lt;&gt;(personService); //实例化接口 IPersonService proxyService = (IPersonService) Proxy.newProxyInstance( IPersonService.class.getClassLoader(), new Class[]{IPersonService.class}, myInvocationHandler); String name = proxyService.getName(&quot;1&quot;); System.out.println(&quot;main: &quot; + name); }} 动态代理处理器 123456789101112131415public class MyInvocationHandler&lt;T&gt; implements InvocationHandler { private T target; public MyInvocationHandler(T target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //invoke是异步执行，所以只能保证方法执行前 System.out.println(&quot;方法执行前输出******&quot;); Object result = method.invoke(target,args); return result; }}","link":"/2022/11/26/%E5%9F%BA%E4%BA%8ESocket%E5%AE%9E%E7%8E%B0%E7%AE%80%E6%98%93RPC%E8%B0%83%E7%94%A8/"},{"title":"Spring源码学习(一)","text":"手写Spring、了解Spring启动与Bean手写模拟Spring启动时的操作，了解BeanDefinition和BeanPostProcessor. 创建Bean的大致步骤： 执行构造方法 得到普通对象 进行依赖注入 执行初始化前操作 执行初始化操作 执行初始化后操作 Spring启动后做了哪些事？ 扫描包 创建单例Bean 扫描包 从配置类中加载需要管理的Bean 处理Bean，将所有Bean封装为BeanDefinition存入BeanDefinitionMap 过滤单例Bean，创建单例Bean对象，存入单例池：SingletonMap 过滤BeanPostProcessor，并创建对象存入beanPostProcessorList 注意：BeanDefinitionMap中存了所有的Bean，单例池中只存了单例的Bean，BeanPostProcessorList中只存了实现了BeanPostProcessList的类 创建单例Bean 遍历单例池 进行依赖注入 遍历BeanPostProcessorList,执行初始化之前的操作 判断该类有无实现InitializingBean接口，实现则进行初始化操作 遍历BeanPostProcessorList,执行初始化之后的操作 判断改类有无实现Aware接口，有则进行回调操作 重要概念BeanDefinitionBean信息的封装类，其中包含Bean的类型、作用范围（单例、原型）、是否懒加载等Spring启动时会把所有的Bean都封装为BeanDefinition BeanPostProcessorBeanPostProcessor是Spring提供的接口，如果类实现了该接口表示在所有bean创建时，会执行该类中的初始化前和初始化后操作。这是Spring中非常重要的机制，Aop就是通过BeanPostProcessor实现的 需要注意的是，BeanPostProcessor对所有Bean生效，而初始化、回调这些接口只对实现了这些接口的Bean生效。 Aop是如何利用BeanPostProcessor机制实现切面的通过BeanPostProcessor创建代理类，并将代理类返回，替换掉原先的普通对象，这样创建出的Bean就是代理对象。、 代码举例手写SpringApplicationContenxt类其中主要包含了两个对外的方法： 构造方法：传入配置对象，获取扫描路径进行扫描 getBean方法，获取Bean12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class RxwsApplicationContext { private Class configClass; //存放所有BeanDefinition private Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new HashMap&lt;&gt;(); //单例池 private Map&lt;String, Object&gt; singletonObjects = new HashMap&lt;&gt;(); //存放所有BenaPostProcessor private List&lt;BeanPostProcessor&gt; beanPostProcessorList = new LinkedList&lt;&gt;(); public RxwsApplicationContext(Class configClass) throws Exception { this.configClass = configClass; //扫描Bean scanBean(); //实例化Bean for (String key : beanDefinitionMap.keySet()) { BeanDefinition beanDefinition = beanDefinitionMap.get(key); if (&quot;singleton&quot;.equals(beanDefinition.getScope())) { Object bean = createBean(key, beanDefinition); singletonObjects.put(key, bean); } } } /** * 获取Bean * * @param beanName * @return */ public Object getBean(String beanName) throws Exception { if (!beanDefinitionMap.containsKey(beanName)) { throw new NullPointerException(&quot;Bean不存在&quot;); } BeanDefinition beanDefinition = beanDefinitionMap.get(beanName); if (&quot;singleton&quot;.equals(beanDefinition.getScope())) { //单例Bean从单例池中拿 Object singletonBean = singletonObjects.get(beanName); if (singletonBean == null) { //依赖注入的时候可能作为属性的bean还没有创建 singletonBean = createBean(beanName, beanDefinition); singletonObjects.put(beanName, singletonBean); } return singletonBean; } else { Object prototypeBean = createBean(beanName, beanDefinition); return prototypeBean; } }} 创建bean大部分功能和机制都是在创建bean时进行处理的。具体就是在创建后逐个去判断有没有实现某个接口，然后调用接口的方法 12345678910111213141516171819202122232425262728293031323334private Object createBean(String beanName, BeanDefinition beanDefinition) throws Exception { Class clazz = beanDefinition.getType(); Object instance = null; instance = clazz.getConstructor().newInstance(); //依赖注入 Field[] declaredFields = clazz.getDeclaredFields(); for (Field field : declaredFields) { if (field.isAnnotationPresent(Autowire.class)) { field.setAccessible(true); field.set(instance, getBean(field.getName())); } } //初始化前的操作 for (BeanPostProcessor beanPostProcessor : beanPostProcessorList) { instance = beanPostProcessor.postProcessBeforeInitialization(instance, beanName); } //初始化 判断Bean是否实现了InitializingBean接口 if (instance instanceof InitializingBean) { ((InitializingBean) instance).afterPropertiesSet(); } //初始化后的操作 for (BeanPostProcessor beanPostProcessor : beanPostProcessorList) { instance = beanPostProcessor.postProcessAfterInitialization(instance, beanName); } //检查回调，以BeanNameAware为例 if (instance instanceof BeanNameAware) { ((BeanNameAware) instance).setBeanName(beanName); } return instance;} 扫描包扫描包，扫描是从Target中拿到class文件，然后加载为类去操作的，扫描是就将Bean添加到上文提到的BeanDefinitionMap 、单例池 、 BeanProcessorList 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private void scanBean() throws Exception { if (configClass.isAnnotationPresent(ComponentScan.class)) { ComponentScan componentScanAnnotation = (ComponentScan) configClass.getAnnotation(ComponentScan.class); String path = componentScanAnnotation.value(); path = path.replace(&quot;.&quot;, &quot;/&quot;); //通过类加载器从target中获取所有class文件 ClassLoader appClassLoader = RxwsApplicationContext.class.getClassLoader(); URL resource = appClassLoader.getResource(path); File files = new File(resource.getFile()); if (files.isDirectory()) { for (File file : files.listFiles()) { //D:\\package\\workspace\\idea\\mySpring\\target\\classes\\rxws\\UserService.class String absolutePath = file.getAbsolutePath(); absolutePath = absolutePath.substring(absolutePath.indexOf(&quot;rxws&quot;), absolutePath.indexOf(&quot;.class&quot;)); //rxws.OrderService absolutePath = absolutePath.replace(&quot;\\\\&quot;, &quot;.&quot;); //将文件加载进来成为类 Class&lt;?&gt; clazz = appClassLoader.loadClass(absolutePath); //判断类有没有添加component注解，没有添加注解的不做处理 if (clazz.isAnnotationPresent(Component.class)) { //如果类实现了BeanPostProcessor接口，则放入BeanPostProcessorList不放入单例池 if (BeanPostProcessor.class.isAssignableFrom(clazz)) { //如果类实现了BeanPostProcessor接口，则放入beanProcessor集合中 BeanPostProcessor beanPostProcessor = (BeanPostProcessor) clazz.getConstructor().newInstance(); beanPostProcessorList.add(beanPostProcessor); } else { BeanDefinition beanDefinition = new BeanDefinition(); String beanName = getBeanName(clazz); //判断是单例还是原型 if (clazz.isAnnotationPresent(Scope.class)) { //根据值判断是不是单例 Scope scopeAnnotation = clazz.getAnnotation(Scope.class); String scopeValue = scopeAnnotation.value(); beanDefinition.setScope(scopeValue); } else { beanDefinition.setScope(&quot;singleton&quot;); } //将bean存入map beanDefinition.setType(clazz); beanDefinitionMap.put(beanName, beanDefinition); } } } } }} 生成BeanName，Spring可以帮我们生成beanName，用户也可以自己指定 123456789private String getBeanName(Class clazz) throws Exception { Component componentAnnotation = (Component) clazz.getAnnotation(Component.class); String beanName = componentAnnotation.name(); if (&quot;&quot;.equals(beanName)) { //JDK提供的方法，根据类名首字母小写生成一个名称 beanName = Introspector.decapitalize(clazz.getSimpleName()); } return beanName;} 其他 扫描包时应该也包含子包，上文有子包会报错 创建Bean时会进行构造方法推断，上文直接使用无参构造 属性依赖注入时是根据类型去找bean，上文是根据字段名去找bean 依赖注入，即@Autowire实际上是通过BeanPostProcesor机制去实现的，上文是在创建Bean时实现的。 遇到的问题： 当在BeanPostProcessor中使用了代理之后一定把代理对象复制给返回的Bean，不然给用户使用的还是普通对象，代理不会生效。","link":"/2022/12/01/Spring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E4%B8%80/"},{"title":"Spring源码学习(二) 扫描Bean","text":"查看spring源码中扫描Bean的代码 扫描找到需要spring管理的类，并存入到beanDefinitionMap中。主要步骤如下： 步骤一：扫描出需要spring管理的类，封装为BeanDefinition 步骤二：填充BeanDefinition的属性 步骤三：判断BeanName是否重复 步骤四：注册Bean 源码查看去除了日志打印、参数非空判断、异常抛出 扫描入口：1ClassPathBeanDefinitionScanner.scan(String... basePackages) scan()传入包扫描路径，返回最后扫描到的Bean数量，主要看doScan方法123456789public int scan(String... basePackages) { int beanCountAtScanStart = this.registry.getBeanDefinitionCount(); doScan(basePackages); if (this.includeAnnotationConfig) { AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registr); } return (this.registry.getBeanDefinitionCount() - beanCountAtScanStart);} doScan() 步骤一：见下文 步骤二：经过步骤一之后BeanDefinition中只有一个class名称，没有其他属性，步骤二就是填充属性，如BeanName、是单例还是多例、是否懒加载等步骤三：检查Spring容器中是否已经存在该beanName，如果存在相同的BeanName且两个类不相同则抛出异常，开发中常见的BeanName重复就是在这里抛出的步骤四：注册Bean ，即将BeanDefinition添加到beanDefinitionMap中1234567891011121314151617181920212223242526272829303132333435protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) { Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;&gt;(); for (String basePackage : basePackages) { //步骤一：扫描出所有的BeanDefinition Set&lt;BeanDefinition&gt; candidates =findCandidateComponents(basePackage); //步骤二：填充BeanDefinition的属性 for (BeanDefinition candidate : candidates) { ScopeMetadata scopeMetadata =this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); //从Component中取value值，如果没有就调用JDK的方法生成名字 String beanName =this.beanNameGenerator.generateBeanName(candidate,this.registry); if (candidate instanceof AbstractBeanDefinition) { postProcessBeanDefinition((AbstractBeanDefinition) candidate,beanName); } if (candidate instanceof AnnotatedBeanDefinition) { // 解析@Lazy、@Primary、@DependsOn、@Role、@Description AnnotationConfigUtils.processCommonDefinitionAnnotations((AnotatedBeanDefinition) candidate); } //步骤三：判断BeanName是否重复 if (checkCandidate(beanName, candidate)) { BeanDefinitionHolder definitionHolder = newBeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetaata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); //步骤四:注册Bean，这里的this.registery就是scan方法中的registry registerBeanDefinition(definitionHolder, this.registry); } } } return beanDefinitions;} 步骤一，扫描出需要spring管理的类，封装为BeanDefinition 1.1: 加载basePackage下所有的文件资源，得到resources 1.2: 遍历resources创建每个类的元数据读取器元数据读取器中包含：类名称、类上的注解、方法上的注解、实现的口名称、继承的类名称、内部类列表等信息 1.3: 判断该类是否匹配排除过滤器和包含过滤器spring默认添加了一个包含过滤器，如果该类有Component注解，就会匹配包含过滤器 1.4 判断是否为独立的类、接口、抽象类。非独立类、接口、抽象类都不创建Bean其中抽象类中如果有方法贴了注解@Lookup注解，该接口也会创建Bean（见拓展）什么是独立的类？最顶层的类和静态内部类是独立的类，其他不，比如非静态的内部类 判断有无/resources/META-INF/spring.components索引文件。如果存在索引文则从改文件中扫描Bean，就不从Target中去扫描了，这样更快 12345678public Set&lt;BeanDefinition&gt; findCandidateComponents(String basePackage) { if (this.componentsIndex != null &amp;&amp; indexSupportsIncludeFilters()) { return addCandidateComponentsFromIndex(this.componentsIndex,basePackage); } else { return scanCandidateComponents(basePackage); }} 没有索引文件的情况，从Target中去扫描 123456789101112131415161718192021222324252627private Set&lt;BeanDefinition&gt; scanCandidateComponents(String basePackage) { Set&lt;BeanDefinition&gt; candidates = new LinkedHashSet&lt;&gt;(); //(1.1)获取basePackage下所有的文件资源 String packageSearchPath = &quot;classpath*:&quot; +resolveBasePackage(basePackage) + &quot;/**/*.class&quot;; Resource[] resources =getResourcePatternResolver().getResources(packageSearchPath); //D:/package/workspace/.../com/xxx/AppConfig.class for (Resource resource : resources) { if (resource.isReadable()) { //(1.2):遍历resources创建每个类的元数据读取器 MetadataReader metadataReader =getMetadataReaderFactory().getMetadataReader(resource); // (1.3):excludeFilters、includeFilters判断 if (isCandidateComponent(metadataReader)) { //生成BeanDefinition，通过扫描生成的就是ScannedGenericBeanDeinition，还有其他类型，比如通过XML配置的就是XmlBeanDefinitioReader ScannedGenericBeanDefinition sbd = newScannedGenericBeanDefinition(metadataReader); sbd.setSource(resource); //(1.4):判断是否为独立的类，是否为接口、抽象类。 if (isCandidateComponent(sbd)) { candidates.add(sbd); } } } } return candidates;} 拓展 JFR：jdk提供的监控程序运行的性能参数，例如执行时间 @Lookup注解使用场景：123456789101112131415161718192021222324252627@Component@Scope(&quot;prototype&quot;)public class User{}@Componentpublic class Person(){ @Autowire private User user; public void test(){ System.out.println(user); }}public class Test { public static void main(String[] args) { // 创建一个Spring容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(AppConfig.class); Person person = (Person) applicationContext.getBean(&quot;person&quot;); person.test(); person.test(); person.test(); }} 以下代码打印出的三个user是同一个对象还是三个对象？是一个对象。尽管User是一个多例对象，但是Person是单例的，创建Person进行依赖注入时已经把User创建好了，所以使用user属性时不会再创建要想实现多例的效果，就可以使用@Lookup注解：1234567891011121314@Componentpublic class Person(){ @Autowire private User user; public void test(){ System.out.println(anyName()); } @Lookup public User anyName(){ return any; }}","link":"/2022/12/04/Spring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E4%BA%8C-%E6%89%AB%E6%8F%8FBean/"},{"title":"Spring源码学习(三) Bean的生命周期","text":"说明spring创建Bean的过程 创建Bean入口： 1org.springframework.beans.factory.support.DefaultListableBeanFactory#preInstantiateSingletons 概念抽象BeanDefinition以下代码中注入的person生成的BeanDefinition就是抽象的，抽象的BeanDefinition是不会实例化的，它的作用主要是BeanDefinition的属性继承这里的集成与类的集成无关，且BeanDefinition的集成并不要求父BeanDefinition是抽象的 12&lt;bean id=&quot;person&quot; class=&quot;com.zhouyu.service.Person&quot; scope=&quot;prototype&quot; abstract=true /&gt;&lt;bean id=&quot;user&quot; class=&quot;com.zhouyu.service.User&quot; parent=&quot;person&quot;/&gt; 合并BeanDefinition 如果有BeanDefinition继承的情况，则会合并实例化子BeanDefinition时会使用父的属性，当然如果子中指定了属性，就用子的，不指定就用父的。比如上文中person是多例的，而user没有指定scope(默认是单例)，则user就会是多例的 合并会生成一个新的RootBeanDefition，不会去修改beanDefinitionMap中的元素。实例化时用RootBeanDefinition去实例化 合并时如果BeanDefinition有parent，则合并，取出parent中属性去判断、去合并，如果没有parent，则直接将BeanDefinition转化为RootBeanDefinition 合并时存在多层parent的情况，用递归解决 FactoryBeanFactory就是由用户自己去创建Bean，通过FactoryBean创建的Bean只会经历初始化后的步骤，不会经历初始化和初始化前的步骤（因为要实现AOP，所以要实现初始化后的步骤）定义FactroyBean 123456789101112131415@Componentpublic class ZhouyuFactoryBean implements FactoryBean { @Override public Object getObject() throws Exception { UserService userService = new UserService(); return userService; } @Override public Class&lt;?&gt; getObjectType() { return UserService.class; }} 此时通过BeanName: zhouyuFactoryBean拿到的Bean就是UserService类型的，通过BeanName：&amp;zhouyuFactoryBean就可以拿到ZhouyuFactoryBean类型的Bean。 FactoryBean会生成两个Bean，一个FactoryBean，一个真实的Bean，FactoryBean存放在单例池中，真实的Bean存放在factoryBeanMap中 实现FactoryBean接口时getObject方法是在getBean时调用的，如果实现的是SmartFactoryBean,且设置了属性之后，getObject方法会在spring启动时执行 创建过程扫描之后就会创建非懒加载的单例Bean 1：循环所有的BeanName，找出非懒加载的单例Bean，并创建 其中处理了FactoryBean，如果是FactoryBean 2：所有的单例Bean创建之后，再循环所有的BeanName，找出实现了SmartInitializingSingleton接口的类，并执行它的afterSingletonsInstantiated()方法 注意该方法是所有的非懒加载的单例Bean创建完成后调用的 创建过程代码代码中省略了日志、JDK安全管理器、JFR 12345678910111213141516171819202122232425262728293031323334353637383940@Overridepublic void preInstantiateSingletons() throws BeansException { List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); for (String beanName : beanNames) { // 获取合并后的BeanDefinition RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) { if (isFactoryBean(beanName)) { // 获取FactoryBean对象 Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) { FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp;((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); if (isEagerInit) { // 创建真正的Bean对象(getObject()返回的对象) getBean(beanName); } } } else { // 创建Bean对象 getBean(beanName); } } } // 所有的非懒加载单例Bean都创建完了后 for (String beanName : beanNames) { Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) { SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; //执行用户定义的方法 smartSingleton.afterSingletonsInstantiated(); } }} getBean()方法在创建Bean过程中，具体的创建是非常重要的。上文一笔带过，现在详细了解。 getBean方法虽然名字叫get，但如果获取不到就会去创建Bean，在Spring启动后创建Bean时调用getBean实际上就是去创建，用户在获取Bean时也会调用，是真的只是去获取，因为此时非懒加载单例Bean已经创建好了。 转化BeanNamegetBean方法传进来的name可能是&amp;xxx或者是别名，transformedBeanName会处理这个name &amp;xxx处理为xxx ，别名处理为真名 尝试去获取Bean先从单例池中去取，取不到再去父容器中取，还取不到就开始创建 检查RootBeanDefinition检查是不是抽象的类，是则报错，检查有无@DependsOn引起的循环依赖 根据scope去创建Bean如果是单例的则创建并存入单例池，原型的则直接创建，其他Scope做相应处理如scope=request，也会在创建后将Bean存入map中，以此来保证同一个请求中用一个BeanName取到的是同一个对象 检查取到的Bean类型是否匹配 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117protected &lt;T&gt; T doGetBean(String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) { // 1：转化BeanName String beanName = transformedBeanName(name); Object beanInstance; //从单例池中获取，如果存在直接返回了，注意这里会执行FactoryBean的getObject方法 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) { if (logger.isTraceEnabled()) { if (isSingletonCurrentlyInCreation(beanName)) { logger.trace(&quot;Returning eagerly cached instance of singleton bean '&quot; + beanName + &quot;' that is not fully initialized yet - a consequence of a circular reference&quot;); } else { logger.trace(&quot;Returning cached instance of singleton bean '&quot; + beanName + &quot;'&quot;); } } // 如果sharedInstance是FactoryBean，那么就调用getObject()返回对象 beanInstance = getObjectForBeanInstance(sharedInstance, name, beanName, null); } //如果单例池中没有 else{ // Fail if we're already creating this bean instance: // We're assumably within a circular reference. if (isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } //尝试从父容器中去获取Bean BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) { // Not found -&gt; check parent. // &amp;&amp;&amp;&amp;xxx----&gt;&amp;xxx String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) { return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); } else if (args != null) { // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); } else if (requiredType != null) { // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); } else { return (T) parentBeanFactory.getBean(nameToLookup); } } if (!typeCheckOnly) { markBeanAsCreated(beanName); } if (requiredType != null) { beanCreation.tag(&quot;beanType&quot;, requiredType::toString); } //开始创建，先把RootBeanDefinition拿出来 RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); // 检查BeanDefinition是不是Abstract的 checkMergedBeanDefinition(mbd, beanName, args); // 根据有无@DependsOn注解引起的循环依赖 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { // dependsOn表示当前beanName所依赖的，当前Bean创建之前dependsOn所依赖的Bean必须已经创建好了 for (String dep : dependsOn) { // beanName是不是被dep依赖了，如果是则出现了循环依赖 if (isDependent(beanName, dep)) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Circular depends-on relationship between '&quot; + beanName + &quot;' and '&quot; + dep + &quot;'&quot;); } // dep被beanName依赖了，存入dependentBeanMap中，dep为key，beanName为value registerDependentBean(dep, beanName); // 创建所依赖的bean getBean(dep); } } //根据不同的作用域去创建Bean，单例Bean创建后存入单例池，原型Bean直接创建 if (mbd.isSingleton()) { //这里的方法引用，是在get没有找到的时候去执行的 //getSingleton方法中有添加到单例池的逻辑 sharedInstance = getSingleton(beanName, () -&gt; { return createBean(beanName, mbd, args); }); //每个Scope最终都会调用这个方法，这个方法会处理FactoryBean，如果你传的是&amp;xxx,上文已经处理过名字了(beanName)，但是这里会把原name也传进去，用来判断你想要的是FactoryBean还是真实Bean beanInstance = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); } //原型Bean else if (mbd.isPrototype()) { Object prototypeInstance = null; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); afterPrototypeCreation(beanName); } //scope是spring启动的时候注册进容器的，springMVC、SpringBoor中会注入request、session的Scope，在这里就会处理 //比如保证同一个请求中同一个BeanName获取到的Bean是同一个 else { String scopeName = mbd.getScope(); if (!StringUtils.hasLength(scopeName)) { throw new IllegalStateException(&quot;No scope name defined for bean ´&quot; + beanName + &quot;'&quot;); } Scope scope = this.scopes.get(scopeName); if (scope == null) { throw new IllegalStateException(&quot;No Scope registered for scope name '&quot; + scopeName + &quot;'&quot;); } try { // session.getAttriute(beaName) setAttri Object scopedInstance = scope.get(beanName, () -&gt; { beforePrototypeCreation(beanName); return createBean(beanName, mbd, args); afterPrototypeCreation(beanName); }); beanInstance = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); } catch (IllegalStateException ex) { throw new ScopeNotActiveException(beanName, scopeName, ex); } } // 检查通过name所获得到的beanInstance的类型是否是requiredType return adaptBeanInstance(name, beanInstance, requiredType);} createBean方法getBean中最重要的方法就是createBean，其中包含了Bean的依赖注入、初始化前、初始化、初始化后等 概念BeanPostProcessor的缓存spring中有很多类型BeanPostProcessor的子接口，spring会将这些子接口根据类型缓存，调用时直接从缓存中拿到然后遍历省去了多次去找BeanPostProcessor的实现类。所谓的缓存应该就是一个Map或者List直接存在内存中 InstantiationAwareBeanPostProcessor1234567891011121314public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor { @Nullable default Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException {return null;} default boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException {return true;} @Nullable default PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) {return null;} @Deprecated @Nullable default PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException {return pvs;}} BeanPostProcessor的子接口，调用时机是Bean实例化前，如果定义了这个接口的实现类，spring会在实例化Bean之前去调用实现类中的postProcessBeforeInstantiation方法这个方法的参数是Class类型，因为此时Bean还没有被实例化，在这个方法中你可以用自己的逻辑去实例化Bean，将实例化后的Bean返回，以此来替代spring的实例化逻辑 。这里可以做很多事，甚至你可以在创建UserService时直接返回个OrderService 注意：如果定义了多个InstantiationAwareBeanPostProcessor的实现类，会循环执行，但是实例化应该只有一次，所以如果执行到某一个processor时返回了对象，则不再执行后面的processor返回实例化对象后会调用初始化后的BeanPostProcessor去实现AOP逻辑 MergedBeanDefinitionPostProcessor接口123456public interface MergedBeanDefinitionPostProcessor extends BeanPostProcessor { void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName); default void resetBeanDefinition(String beanName) {}} 在Bean实例化之后处理，主要是对RootBeanDefinition的属性进行操作 createBean方法代码此时类还没有被实例化，所以RootBeanDefinition中的class属性的值是String，即类名，实例化后就会被赋值为Class类型 加载类，其中就会根据RootBeanDefinition的class属性判断是否已经加载，还会去选择类加载器，最终返回Class对象 处理InstantiationAwareBeanPostProcessor接口的postProcessBeforeInstantiation()方法 如果InstantiationAwareBeanPostProcessor接口的逻辑没有返回对象，则去调用doCreateBean方法去创建对象12345678910111213141516171819202122232425protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args){ RootBeanDefinition mbdToUse = mbd; // 1:加载类 Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) { mbdToUse = new RootBeanDefinition(mbd); //设置class属性 mbdToUse.setBeanClass(resolvedClass); } // 处理@LookUp注解 mbdToUse.prepareMethodOverrides(); // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 2：处理InstantiationAwareBeanPostProcessor接口 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); //如果InstantiationAwareBeanPostProcessor接口的逻辑返回了对象，则直接使用返回的对象，不再执行后面的操作 if (bean != null) { return bean; } //3：doCreateBean方法中去实例化 Object beanInstance = doCreateBean(beanName, mbdToUse, args); return beanInstance;} doCreateBean方法 实例化Bean，其中包含了对@Bean的处理、推断构造方法，经过这一步Bean已经被实例化了，但是没有属性 处理MergedBeanDefinitionPostProcessors.postProcessMergedBeanDefinition()方法主要是对RootBeanDefinition的属性做操作，比如指定初始化方法等，指定初始化方法后，该方法会在初始化时执行 循环依赖相关 属性填充 处理InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation() 在这里可以自己进行依赖注入，注入后spring不会对该属性做处理 处理spring自带的依赖注入，理解为不使用@Autowire、@Resource而是使用by_name by_type进行依赖注入，常在xml中注入Bean时使用 调用InstantiationAwareBeanPostProcessor.postProcessProperties() 去处理@Autowire、@Resource、@Value，进行依赖注入经过这一步，对象已经有属性了 初始化 初始化前，处理BeanPostProcessor.postProcessBeforeInitialization()方法 执行初始化方法，就是RootBeanDefinition中指定的初始化方法 初始化后，处理BeanPostProcessor.postProcessAfterInitialization()方法，也是AOP主要实现的位置123456789101112131415161718192021222324252627282930313233343536protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args){ // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) { // 有可能在本Bean创建之前，就有其他Bean把当前Bean给创建出来了（比如依赖注入过程中） instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); } //判断该Bean是不是在Spring启动时就已经创建好了，如果已经创建就直接拿（主要针对FactoryBean） if (instanceWrapper == null) { // 1：实例化Bean，其中包含了对@Bean的处理、推断构造方法 instanceWrapper = createBeanInstance(beanName, mbd, args); } Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) { mbd.resolvedTargetType = beanType; } // 后置处理合并后的BeanDefinition // 2：处理MergedBeanDefinitionPostProcessors接口的逻辑， synchronized (mbd.postProcessingLock) { if (!mbd.postProcessed) { applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); mbd.postProcessed = true; } } //3：循环依赖相关 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;isSingletonCurrentlyInCreation(beanName)); // Initialize the bean instance. Object exposedObject = bean; // 4：属性填充 populateBean(beanName, mbd, instanceWrapper); // 5：初始化 exposedObject = initializeBean(beanName, exposedObject, mbd); return exposedObject;} createBean方法总结123456789101112131415161718createBean{ 1:加载类 2:InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation() 可以在此自己定义实例化规则，如果返回对象，则不做后面的处理了 3:doCreateBean(){ 1:实例化Bean，经过这一步，就有对象了，但是对象属性没有值 2:处理MergedBeanDefinitionPostProcessors.postProcessMergedBeanDefinition()方法 主要是对RootBeanDefinition的属性做操作，比如指定初始化方法等 3:属性填充populateBean(){ 1:处理InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation() 此时对象已经实例化但是没有属性，在此方法中可以自己进行依赖注入 2:处理spring自带的依赖注入 3:调用InstantiationAwareBeanPostProcessor.postProcessProperties() 去处理@Autowire、@Resource、@Value.经过这一步，对象已经有属性了 } 4:初始化initializeBean(){ 1:初始化前，处理BeanPostProcessor.postProcessBeforeInitialization()方法 2:执行初始化方法，就是RootBeanDefinition中指定的初始化方法 3:初始化后，处理BeanPostProcessor.postProcessAfterInitialization()方法，也是AOP主要实现的位置 } }} 销毁Bean在创建Bean结束后，会扫描Bean的销毁方法，先扫描有无实现接口DisposableBean，再看RootBeanDefinition中有无定义销毁方法，再扫描所有的DestructionAwareBeanPostProcessor，最后将这些销毁分门别类的放入map中，在spring容器正常关闭的时候，逐个去调用 拓展 父容器spring可以有父容器，源码中有很多内容都是如果本容器中找不到，就去父容器中找的代码 @DependsOn注解 123@Component@DependsOn(&quot;orderService&quot;)public class UserService{} 表示userService依赖于orderService，创建userService之前要先创建orderService，和@Autowire作用相同，但底层实现不同由@DependsOn注解引起的循环依赖是无法解决的，会直接报错","link":"/2022/12/06/Spring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E4%B8%89-Bean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"title":"Spring源码学习(四) 依赖注入","text":"spring创建Bean时进行依赖注入，大概流程就是找注入点、进入属性赋值 概念 注入点：添加了@Autowire、@Value、@Resource的字段或者set方法称为注入点 pvs不算是概念，是spring源码中经常出现的一个命名，指BeanDefinition的PropertyValues属性，在依赖注入功能中主要的体现就是如果在MergedBeanDefinitionPostProcessors.postProcessMergedBeanDefinition()方法中指定了某个字段的值(即在pvs中添加键值对，key为字段名)，则依赖注入时不会再进行处理 环境变量(Environment)：spring配置文件中的内容、启动命令中指定的参数都会存到环境变量中，@Value(“${}”)就是从环境变量中获取值 流程依赖注入是在Bean创建过程中进行的，调用的位置是实例化后，初始化前。方法名：populateBean() 123456789101112131415161718createBean{ 1:加载类 2:InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation() 可以在此自己定义实例化规则，如果返回对象，则不做后面的处理了 3:doCreateBean(){ 1:实例化Bean，经过这一步，就有对象了，但是对象属性没有值 2:处理MergedBeanDefinitionPostProcessors.postProcessMergedBeanDefinition()方法 主要是对RootBeanDefinition的属性做操作，比如指定初始化方法等 3:属性填充populateBean(){ 1:处理InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation() 此时对象已经实例化但是没有属性，在此方法中可以自己进行依赖注入 2:处理spring自带的依赖注入 3:调用InstantiationAwareBeanPostProcessor.postProcessProperties() 去处理@Autowire、@Resource、@Value.经过这一步，对象已经有属性了 } 4:初始化initializeBean(){ 1:初始化前，处理BeanPostProcessor.postProcessBeforeInitialization()方法 2:执行初始化方法，就是RootBeanDefinition中指定的初始化方法 3:初始化后，处理BeanPostProcessor.postProcessAfterInitialization()方法，也是AOP主要实现的位置 } }} populateBean() 处理所有的InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation() 方法 处理使用BY_NAME、BY_TYPE方式注入的Bean的属性 处理普通的Bean属性(这里会给属性赋值)，通过InstantiationAwareBeanPostProcessor.postProcessProperties()方法之前说过BeanPostProcessor的处理逻辑，就是在某个时刻把所有的processor拿出来执行其中的某个方法，依赖注入和AOP就是通过这个机制实现的，这里InstantiationAwareBeanPostProcessor有多个子接口，比如AutowiredAnnotationBeanPostProcessor就是专门处理@Autowire注解的，还有处理@Resource注解的等 12345678910111213141516171819202122protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) { ... // 实例化之后，属性设置之前 处理所有的InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation() 方法 ... PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); int resolvedAutowireMode = mbd.getResolvedAutowireMode(); //如果该类标明使用BY_NAME或者BY_TYPE的注入方式，则在这里处理（这两种方式已经过期） if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) {...} //遍历所有的InstantiationAwareBeanPostProcessor，执行其中的postProcessProperties方法 for (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) { // 这里会调用AutowiredAnnotationBeanPostProcessor的postProcessProperties()方法 PropertyValues pvsToUse = bp.postProcessProperties(pvs,bw.getWrappedInstance(), beanName); ... } ... // 如果当前Bean中的BeanDefinition中设置了PropertyValues，那么最终将是PropertyValues中的值，覆盖@Autowired ...} 以Autowire注解的postProcessorProperties()方法为例 findAutowiringMetadata找到所有注入点 inject处理注入点，进行赋值1234567@Overridepublic PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) { // 找注入点（所有被@Autowired注解了的Field或Method） InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs); metadata.inject(bean, beanName, pvs); return pvs;} 找注入点 spring内部的方法可能在不同场景会被调用很多次，所以经常看到这样的逻辑：先判断缓存中是否存在，如果存在则返回，不存在则创建并存入缓存。 buildAutowiringMetadata()方法去找注入点 注入点找到后被封装为InjectionMetadata类型，并存入缓存 1234567891011121314151617181920private InjectionMetadata findAutowiringMetadata(String beanName, Class&lt;?&gt; clazz, @Nullable PropertyValues pvs) { // Fall back to class name as cache key, for backwards compatibility with custom callers. String cacheKey = (StringUtils.hasLength(beanName) ? beanName : clazz.getName()); // Quick check on the concurrent map first, with minimal locking. InjectionMetadata metadata = this.injectionMetadataCache.get(cacheKey); if (InjectionMetadata.needsRefresh(metadata, clazz)) { synchronized (this.injectionMetadataCache) { metadata = this.injectionMetadataCache.get(cacheKey); if (InjectionMetadata.needsRefresh(metadata, clazz)) { if (metadata != null) { metadata.clear(pvs); } // 解析注入点并缓存 metadata = buildAutowiringMetadata(clazz); this.injectionMetadataCache.put(cacheKey, metadata); } } } return metadata;} buildAutowiringMetadata()方法 源码位置：org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor#buildAutowiringMetadata 判断该注入点需不需要赋值，如果是基本类型就不进行处理 遍历所有字段，检查是不是有@Autowire、@Value、@Inject注解 遍历所有方法，检查是不是有这三个注解 最终返回诸如点列表 注意： 判断是不是基本类型的方式：判断该类的全限定名是不是”java. “开头 static修饰的方法和字段不会被添加注入点列表中 inject()方法：处理注入点，进行赋值InstantiationAwareBeanPostProcessor多个实现类中inject方法的实现都不一样，这里依然以处理@Autowire注解的实现类为例。 inject方法中主要的几种情况： 如果所需类型是Optional、ObjectFactory都会单独进行处理 如果字段或者方法参数前有@Lazy注解，则生成一个代理对象，并返回。 生成代理对象，在用户使用该Bean的方法时，代理对象才会去找Bean的属性并进行注入 如果贴的注解时@Value，则根据@value的value给属性进行赋值 @Value有三种方式：字符串、${}占位符、#{}EL表达式 如@Value(“#{userService}”),字符串会直接赋值，占位符会从环境变量中取值，el表达式会根据表达式找Bean 如果字段是个Collection、map，spring会找到所有符合类型的Bean进行赋值,如Map:12@AutowireMap&lt;String,UserService&gt; userservices; //对于map，key必须是String。最后的结果就是找到所有的UserService类型的Bean存入map 处理正常的使用@Autowire注解场景，先根据类型找Bean，最后确定一个Bean并赋值1234根据类型找Bean，如果找到多个，会依次做以下处理：判断有没有指定主Bean，使用@primary实现判断有没有指定优先级，使用@priority实现根据name确定用哪一个","link":"/2022/12/11/Spring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%9B%9B-%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"},{"title":"Spring源码学习(五) 循环依赖","text":"什么是循环依赖？循环依赖是spring中的问题，普通的java项目不会有循环依赖。Spring中出现的循环依赖有三种情况：自我依赖、循环依赖、多组依赖 什么是循环依赖？循环依赖是spring中的问题，普通的java项目不会有循环依赖。 123456789// A依赖了Bclass A{ public B b;}// B依赖了Aclass B{ public A a;} 以上代码的逻辑就会产生循环依赖，创建A时需要依赖B，创建B时又需要A，陷入了循环。Spring中出现的循环依赖有三种情况：自我依赖、循环依赖、多组依赖。 解决思想解决循环依赖的关键在于打破循环。如何打破循环呢？spring中将A的半成品对象存入缓存(map)中，创建B时，如果没有A的成品对象，就使用A的半成品对象。以此来打破循环。 B依赖的半成品对象会在A创建完成后变成成品对象,因为指向同一块存储空间。 spring如何解决循环依赖 为什么需要三级缓存Spring中使用三级缓存来解决循环依赖。按照上文的思想，解决循环依赖只需要一个缓存即可，为什么Spring要使用三级缓存？ 为了遵从Spring的设计思想 为了代码逻辑清晰 如果只使用一个缓存，对象实例化后就把未进行属性填充半成品对象存入缓存中。这样设计有两个问题： 这个缓存中既有半成品对象，也有成品对象，容易造成空指针，代码逻辑不清晰 如果对象进行了AOP，那么用户最终得到的是代理对象，但是缓存中存的是普通对象 解决第一个问题：再加一个缓存，分别存储成品对象和半成品对象。存储成品对象即Spring中的第一级缓存: singletonObjects存储半成品对象即Spring中的第二级缓存：earlySingletonObjects 解决第二个问题：提前进行AOP，AOP本来是在初始化后中进行的，如果出现了循环依赖，将AOP过程提前到实例化后。这样在实例 化后得到的半成品对象可能是普通对象也可能是代理对象。实例化后处理AOP的这一段逻辑额也存在缓存中，即Spring中的第三级缓存：singletonFactoies(可能因为存的是生成半成品对象的方法，所以名字以factory结尾) 为什么不把所有的Bean都在实例化后进行AOP？因为这违背了Spring先创建所有的Bean，再进行初始化的设计思想。 使用三级缓存的流程Spring中使用三级缓存解决循环依赖的流程： 在实例化后将一个方法引用(getEarlyBeanReference())存入第三级缓存，执行这个方法可以获得一个半成品对象，可能是普通对象，也可能是普通对象。在填充属性时，一次从第一级、第二级、第三级缓存中获取对象，进行填充。 从第三级缓存中获取到半成品对象后，会将该对象从第三级缓存中移除，将半成品对象添加到第二级缓存，下次找的时候就能从第二级缓存中拿到了。对象创建完成之后会注册对象，即将对象从第二级缓存中移除，添加到第一级缓存中。下次从第一级缓存就直接拿到了。 三级缓存 三级缓存分别是什么时候存入的？实例化后存入第三级缓存，从第三级缓存中获取到半成品对象后，存入第二级缓存，对象创建完成后存入第一级缓存。 三级缓存分别是什么时候使用的？填充属性时依次从三级缓存中寻找对应的Bean 三级缓存分别存的是什么？ 一级缓存：即单例池，存储成品对象 二级缓存：存储半成品对象 三级缓存：存储的是获取半成品的方法引用。可以说存的是工厂对象 三级缓存的意义？三个缓存的意义都是打破循环，解决循环依赖。为了逻辑清晰增加了第二级循环，为了处理AOP且不违背设计思想，增加了第三级循环。所以如果要说三级缓存各级缓存的意义，我觉得可以说：第三级缓存打破了循环，第二级循环和第一级循环使代码逻辑清晰。 补充 判断是否出现了循环依赖？在创建Bean时，将这个Bean存入一个Map中，表示正在创建，创建结束后移除。其他Bean在创建时，如果发现依赖了这个对象，且这个对象存在于Map中，则说明出现了循环依赖。","link":"/2022/12/20/Spring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E4%BA%94-%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/"}],"tags":[{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"运维","slug":"运维","link":"/tags/%E8%BF%90%E7%BB%B4/"},{"name":"RocketMq","slug":"RocketMq","link":"/tags/RocketMq/"},{"name":"消息中间件","slug":"消息中间件","link":"/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"消息队列","link":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RPC","slug":"RPC","link":"/tags/RPC/"},{"name":"Socket","slug":"Socket","link":"/tags/Socket/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"}],"categories":[{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"消息中间件","slug":"消息中间件","link":"/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RPC","slug":"RPC","link":"/categories/RPC/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"}],"pages":[]}