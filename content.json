{"posts":[{"title":"Linux服务器之间挂载共享目录","text":"Linux现有比较成熟的解决方案有两种，一种是NFS远程挂载，另一种是Samba共享目录。下面使用NFS，即网络文件系统（Network File System）分布式文件系统协议 环境 服务端-A服务器 121.4.247.245 Centos 客户端-B服务器 1.12.221.166 Ubuntu 步骤服务端设置共享目录，客户端挂载目录 服务端-A服务器 安装NFS 由于NFS是依赖于RPC协议来进行的协议传输，所以，此时需同时安装，NFS 和 RPC 两个应用程序 1yum -y install nfs-utils rpcbind 设置共享目录 NFS的配置文件在/etc/exports，内容默认为空。配置格式为：目录位置 客户机地址(权限选项) 123vim /etc/exports//添加如下内容/sharetest 1.12.221.166(insecure,rw,no_root_squash,no_all_squash,sync) 其中，/sharetest是服务器端要共享出来的目录，1.12.221.166是客户端的ip，rw代表客户端可以对共享目录进行读写操作。 启动NFS服务12345678#启动rpc服务(stop关闭)systemctl start rpcbind#启动nfs服务(stop关闭)systemctl start nfs#查看rpc服务状态systemctl status rpcbind#查看nfs服务状态systemctl status nfs 查看当前机器已经发布的NFS共享目录1showmount -e 此时共享文件A服务器的配置已经完成，可直接在B服务器进行目录的挂载操作 客户端-B服务器 安装RPC服务1apt-get install rpcbind 挂载1mount -t nfs 121.4.247.245:/data/share /data/store df -h 查看挂载目录 开机自动挂载12vim /etc/fstab121.4.247.245:/sharetest /sharetest nfs defaults,_netdev 0 0 开机自动启动1systemctl enable rpcbind.service 注意：/etc/fstab是用来存放文件系统的静态信息的文件,当系统启动的时候，系统会自动地从这个文件读取信息，并且会自动将此文件中指定的文件系统挂载到指定的目录。如果挂载的格式不正确会导致服务器启动失败，需要进入救援者模式处理，谨慎操作fstab文件。linux之fstab文件详解:https://blog.csdn.net/qq_32907195/article/details/117512634 开机自动挂载可以写脚本开机自动执行，脚本中使用命令挂载 卸载共享目录在客户端服务器卸载 1umount -l /sharetest 卸载后未生效，文件依旧会同步~~~ 其他 如果NFS服务器端的防火墙没有关闭的话，共享目录在挂载的时候就会出现挂载失败，连接超时的问题（mount.nfs:Connection timed out） 服务器端exports的客户端配置选项要加上insecure参数，例如：/sharedata 192.168.10.109(insecure,rw)。 如果不加上insecure参数的话，在挂载共享目录时，可能会提示如下错误：mount.nfs:access denied by server while mounting。 共享文件夹最好设置权限 chmod -R 777 /sharetest","link":"/2022/11/15/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B9%8B%E9%97%B4%E6%8C%82%E8%BD%BD%E5%85%B1%E4%BA%AB%E7%9B%AE%E5%BD%95/"},{"title":"RocketMq入门","text":"介绍 MQ的用处 限流削峰 异步解耦 数据收集：收集业务日志、监控数据、用户行为 RocketMQ基础概念 消息(message): 生产和消费数据的最小单位，每条消息必须属于一个主题 主题(topic): 一类消息的集合，每个主题包含多个消息。一个生产者可以生产多个topic消息，一个消费者只能消费一个topic **标签(Tag)**：为消息设置的标签用于同一个topic下区分不同类型的消息 **队列(Queue)**：存储消息的物理实体，一个topic包含多个Queue，每个Queue中存放的就是该Topic的消息。一个topic中的queue也叫topic中消息的分区。一个queue只能被一个消费者消费 消息标识(MessageId/key): 消息的唯一标识，生产者发送消息会产生一个msgId，消费者接收消息会产生offsetMsgId，用户指定而定业务id叫key 架构 producer：生产消息 consumer：进行消息消费 负载均衡：一个topic中的queue会平均分配给消费者组中的消费者 容错：组中的一个消费者挂掉后，其他的消费者会平分该消费者的queue 消费者组只能消费一个topic的消息，不能同时消费多个topic的消息 一个消费者组中的消费者必须订阅完全相同的topic NameServer：broker和topic路由的注册中心，功能：broker管理、路由信息管理 broker：用于存储和转发消息 工作流程①:启动namerserver -&gt; ②:启动broker -&gt; ③:创建topic -&gt; ④:生产消息 -&gt; ⑤:消费消息1：namerserver因为rockermq的注册中心是无状态的，所以它的broker信息与路由信息需要broker主动发送给nameserver，所以先启动nameserver，关闭时先关闭broker2：创建topic发送消息前应该先创建topic也可以设置自动创建，手动创建topic有两种方式：集群模式和broker模式，区别在于集群模式创建的topic在每个broker中的读写队列数量都是一致的，而broker模式你需要在逐个选择broker进行创建topic，读写队列自然数量自然可以不同。手动创建topic的参数有四个：创建模式、读队列数量、写队列数量、perm。perm用于设置对当前创建Topic的操作权限：2表示只写，4表示只读，6表示读写。3：读写队列生产者将消息写入写队列，消费者从队列中读取消息。在物理上读写队列是同一个队列，一般情况读写队列数量是相同的。但broker模式创建topic时读写队列数量不同，这样是为了缩容。缩容：如现在读写队列数量都为16个，需要缩容为都是8个，且保证消息不丢失。可以先将写队列动态调整为8个，此时只有8个写队列在往里写消息，16个队列在消费消息，待停止写入消息的那8个队列的消息消费完了之后，将读队列的数量修改为8，即实现了缩容 工作原理生产消息 生产过程： Producer发送消息之前，会先向NameServer发出获取 消息Topic的路由信息 的请求 NameServer返回该Topic的 路由表 及 Broker列表 路由表是个map，key是topic名称，value是broker列表，列表中没有地址只有名称，produer通过路由表找到brokername,再从broker列表中找到broker地址 Producer根据代码中指定的Queue选择策略，从Queue列表中选出一个队列，用于后续存储消息 Queue选择算法：无序消息：轮询和最小投递延迟算法 Produer对消息做一些特殊处理，例如，消息本身超过4M，则会对其进行压缩 Producer向选择出的Queue所在的Broker发出RPC请求，将消息发送到选择出的Queue 轮询算法：默认选择的算法，保证消息在队列中均匀的消费消息1发送个队列1，消息2发送给队列2，以此类推。缺点：消息1发送后，生产者要等消息成功发送后再把消息2发送给队列2，不成功下次还是给队列1发送。这样一来可能造成消息在生产者的缓存队列中大量积压，影响性能。 最小投递延迟算法统计每个队列投递消息的延迟，选择最小的队列进行投递，缺点：可能造成一个队列中存放了大量消息，造成消费者消费者能力下降，消息在MQ中积压严重 消息的存储RocketMQ中的消息存储在本地文件系统中，这些相关文件默认在当前用户主目录下的store目录中。 indexFile除了通过通常的指定Topic进行消息消费外，RocketMQ还提供了根据key进行消息查询的功能。该查询是通过store目录中的index子目录中的indexFile进行索引实现的快速查询。当然，这个indexFile中的索引数据是在 包含了key的消息 被发送到Broker时写入的。如果消息中没有包含key，则不会写入。 消费消息 获取消息 **拉取式消费(pull)**：Consumer主动从Broker中拉取消息。实时性弱 拉取消息的时间是用户指定的，拉取时间需要注意平衡,RocketMq默认使用拉取式消费，拉取间隔15秒 推送式消费(push): broker收到消息后主动推送给consumer，实时性高，耗费资源 consumer向其关联的queue注册了监听器，这需要长连接，所以耗费资源(与每个broker建立长连接) **长轮询(long polling)**：消费者定时去broker中获取消息，如果没获取到消息，保持连接一段时间，比如30s，30s内没有消息，则断开连接，30s内有消息，则消费消息且再等30s。中和了pull和push的利弊。 消费消息 广播消费消费者组中的每个消费者都接收topic全量的消息，各自进行消费，一条消息被消费n次，消费进度保存在消费者中 集群消费消费者组中的消费者平摊topic所有的消息，一条消息被消费一次，进度需要共享，所以消费进度存放在broker中 Rebalance机制Relablance机制指当消费者组中的消费者数量发生变化（宕机、新增）时、消费者所订阅的Topic中的Queue数量发生变化时，将Topic中的多个Queue重新分配给消费者的机制。Reblance机制的前提是集群消费。在进行Reblance时，会导致消费暂停，重新分配Queue后继续消费，这可能会导致消息重复或者暂停时间过长导致消息积压。优点是可以提升消费能力 Queue分配算法 平均分配：先根据Queue的数量和消费者的数量计算每个消费者分配的Queue数量，如不能平均分配，则将多于的Queue逐个分配个消费者。 环形平均分配：消费者逐个从Queue队列中领取，与平均分配不同的是，平均分配的Queue是连续的，比如Consumer1会拿到0、1、3的Queue，而环形会拿到0、3、6的Queue 一致hash策略：将consumer的hash值作为Node节点存放到hash环上，然后将queue的hash值也放到hash环上，通过 顺时针 方向，距离queue最近的那个consumer就是该queue要分配的consumer。（分配不均） 同机房分配：根据queue的部署机房位置和consumer的位置，过滤出当前consumer相同机房的queue。然后按照平均分配策略或环形平均策略对同机房queue进行分配 订阅关系一致性错误的订阅关系会导致消费逻辑混乱、丢失消息正确的订阅关系：多个消费者组订阅了多个Topic，并且每个消费者组里的多个消费者实例的订阅关系保持了一致。错误的订阅关系： 一个消费者组中的消费者订阅了不同的Topic 一个消费者组中的消费者订阅了相同的Topic，不同的Tag 一个消费者组中的消费者订阅了不同数量的消费者 消息幂等某个操作执行多次和执行一次对系统的影响都是一样的，则为幂等操作。读操作一般都是幂等的，幂等性一般讨论的都是写操作。对于RocketMq来说，如果出现消息重复，就可能会重复消费影响业务。 RocketMq可能出现的消息重复场景 producer将消息发送给broker，broker持久化消息后因为网络原因没有给produce发送接收到消息的响应，produce会判断为消息发送失败，会重复发送失败的消息，并不会重新生成msgId。 consumer接收到消息后没有给broker成功的响应，broker会重复给consumer发送消息 Rebalance时导致消息重复 通用的幂等性解决方案通常通过幂等令牌实现幂等性操作，如支付操作：producer发送消息时带上幂等令牌，支付中可能是订单号。consumer处理消息时进行三步处理： 检查缓存中有无与令牌相同的key，如存在则认定为重复操作，如不存在则进行下一步 检查数据库中有无该令牌为索引的数据，如存在则认定为重复操作，不存在则进行下一步 进行到这一步就已经认定为未重复，进行业务操作，然后将令牌存入缓存、数据库 为什么缓存中判重后还要在数据库中再次判重？因为为了性能，缓存中一般存的都是有有效期的，存在key过期而不存在的情况 在RocketMq中producer可以在发送消息时将幂等令牌设置为消息的key message.setKey(&quot;XXXXX&quot;) message的标识有三个：msgId(producer生成)、offsetMsgId(broker生成)、key(用户指定的业务唯一标识) 代码举例 依赖，以下案例使用rocketmq-client依赖举例 &lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.9.4&lt;/version&gt; &lt;/dependency&gt; 普通消息消息根据发送类型分为： 同步发送：producer发送一条消息后，收到MQ的响应后发送下一条消息，可靠性高效率低 异步发送：无需等待响应(但会接收响应)，直接发送下一条，可靠性一般、效率一般 单向发送：不接收响应，可靠性差，效率高 producer发送消息 //失败重试次数、默认2次 producer.setRetryTimesWhenSendFailed(3); //发送超时时间，默认3秒，单向消息设置超时时间貌似会报超时错误 //超时错误：sendDefaultImpl call timeout producer.setSendMsgTimeout(5000); //指定新创建的Topic的Queue数量为2，默认为4 producer.setDefaultTopicQueueNums(2); /** * 发送同步消息 * @throws Exception */ @Test public void syncSend() throws Exception { DefaultMQProducer producer = new DefaultMQProducer(&quot;myGroup&quot;); producer.setNamesrvAddr(IP_PORT); producer.start(); byte[] body = &quot;123&quot;.getBytes(); Message msg = new Message(&quot;testSyncTopic&quot;, &quot;test&quot;, body); SendResult send = producer.send(msg); producer.shutdown(); } /** * 发送异步消息 * @throws Exception */ @Test public void asyncSend() throws Exception { DefaultMQProducer producer = new DefaultMQProducer(&quot;myAsyncGroup&quot;); producer.setNamesrvAddr(IP_PORT); producer.start(); byte[] body = &quot;test&quot;.getBytes(); Message msg = new Message(&quot;testSyncTopic&quot;, &quot;test&quot;, body); producer.send(msg, new SendCallback() { @Override public void onSuccess(SendResult sendResult) { //发送成功的回调，sendResult为返回结果 System.out.println(sendResult); } @Override public void onException(Throwable throwable) { //发送失败的异常信息 System.out.println(throwable.getMessage()); } }); //异步发送，如果直接关闭生产者，可能消息还没发完 Thread.sleep(3000); producer.shutdown(); } /** * 发送单单向消息 * @throws Exception */ @Test public void oneWaySend() throws Exception { DefaultMQProducer producer = new DefaultMQProducer(&quot;myAsyncGroup&quot;); producer.setNamesrvAddr(IP_PORT); producer.start(); byte[] body = &quot;test&quot;.getBytes(); Message msg = new Message(&quot;testOneWayTopic&quot;, &quot;test&quot;, body); producer.sendOneway(msg); producer.shutdown(); } consumer接收消息 // 指定采用“广播模式”进行消费，默认为“集群模式” consumer.setMessageModel(MessageModel.BROADCASTING); /** * 接收消息 * @throws Exception */ @Test public void consumer() throws Exception { while (true){ System.out.println(&quot;into&quot;); DefaultMQPushConsumer consumer =new DefaultMQPushConsumer(&quot;myConsumerGroup&quot;); consumer.setNamesrvAddr(IP_PORT); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(&quot;testSyncTopic&quot;,&quot;*&quot;); // consumer.subscribe(&quot;testOneWayTopic&quot;,&quot;*&quot;); consumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext context) { list.forEach(msg-&gt;{ System.out.println(new String(msg.getBody())); }); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); consumer.start(); Thread.sleep(5000); } } 顺序消息顺序消息指的是，严格按照消息的 发送顺序 进行 消费 的消息(FIFO)。 普通消息为什么不是顺序的？producer生产消息后会根据算法(轮询、最小投递)将消息投递到不同的Queue中，每个Queue中虽然是先进先出的，但是不同Queue中的消费速度可不一样，将消息投递到不同的Queue中当然不是顺序的。所以要保证消息的顺序，就要保证消息在同一个Queue中，比如一个订单的三条消息：创建、付款、完成。三条都在一个Queue中。注意:一个Queue只能被一个消费者消费，所以放在一个Queue中就是顺序的 如何保证消息在一个Queue中？ producer设置Topic下的Queue数量为1.称之为全局顺序 producer通过Queue选择算法指定消息投递到哪个Queue中，订单场景中就是设置每个订单的三个消息都能进到同一个Queue中，称之为部分顺序 全局顺序与部分顺序的代码是相同的。Queue选择算法就是通过计算得出消息投递的Queue索引，相同订单的三个消息计算出的索引是相同的，就会被投递到同一队列。常用的方法就是Hash取模，用订单ID%队列数量得到Queue索引 如何完成一次顺序消息的发送、消费？ 保证消息在同一个Queue中 同步发送，顺序消息只能用同步发送(虽然提供了异步方法，但不能保证有序) consumer使用有序消费模式进行消费MessageListenerOrderly 代码注意：订单id是通过send方法的第三个参数传递进去的、消费者中用顺序监听器最后观察消费者的输出，同一个订单的消息都在同一个Queue中 /** * 发送顺序消息 * @throws Exception */ @Test public void syncSend() throws Exception { DefaultMQProducer producer = new DefaultMQProducer(&quot;myGroup&quot;); producer.setNamesrvAddr(IP_PORT); producer.start(); Integer[] orderIds =new Integer[]{111,222,333}; for (Integer i = 0; i &lt; 13; i++) { //有4条消息的orderId是111，这4条消息计算Queue索引时都是相同的，就会被投递到相同的队列中 int index = i%3; Integer orderId = orderIds[index]; byte[] body = orderId.toString().concat(&quot;-&quot;).concat(i.toString()).getBytes(); Message msg = new Message(&quot;testOrderlyTopic&quot;, &quot;test&quot;, body); //传递三个参数：message,选择器,选择器Key 这个选择器key就是内部类方法select()的参数 SendResult sendResult = producer.send(msg, new MessageQueueSelector() { @Override public MessageQueue select(List&lt;MessageQueue&gt; list, Message message, Object key) { Integer orderId = (Integer) key; //计算投递的Queue的索引 int queueIndex = orderId % list.size(); return list.get(queueIndex); } },orderId); } producer.shutdown(); } /** * 接收消息 * @throws Exception */ @Test public void consumer() throws Exception { while (true){ System.out.println(&quot;into&quot;); DefaultMQPushConsumer consumer =new DefaultMQPushConsumer(&quot;myConsumerGroup&quot;); consumer.setNamesrvAddr(IP_PORT); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(&quot;testOrderlyTopic&quot;,&quot;*&quot;); consumer.registerMessageListener(new MessageListenerOrderly() { @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeOrderlyContext consumeOrderlyContext) { list.forEach(entity-&gt;{ int queueId = entity.getQueueId(); String bodyString = new String(entity.getBody()); System.out.println(queueId+&quot;----&quot;+bodyString); }); return ConsumeOrderlyStatus.SUCCESS; } }); consumer.start(); Thread.sleep(500); } } 延时消息延时消息顾名思义就是延迟发送消息，典型的应用场景就是一段时间内未支付，则结束订单。开启订单后，发送一条延时30分钟的消息，30分钟后消费者收到消息，拿到订单号，检查该订单是否已经支付，如果未支付则结束订单，将商品放回商品库。 Rocketmq中不能设置延时时间，只能设置延时等级，不同的延时等级对应不同的延时时间，延时等级从1开始。延时等级定义在RocketMQ服务端的 MessageStoreConfig 类中。如果需要自定义的延时等级，可以通过在broker加载的配置中新增如下配置（例如下面增加了1天这个等级1d）。配置文件在RocketMQ安装目录下的conf目录中。 messageDelayLevel = 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 1d 实现原理producer将消息发送到broker后，broker会将消息先放到commitlog中，然后再分发到对应的queue，在分发之前会判断消息有无延时，如没有延时，则正常发送，如果有延时等级将会修改消息的topic为SCHEDULE_TOPIC_XXXX，并将消息发送到该topic的queue下。broker中有个延迟消息服务类ScheuleMessageService，会消费该主题下的消息，该服务类在到达延时时间后将消息的延时等级设为0，重新投递到原topic中。 代码举例比较简单 msg.setDelayTimeLevel(3); 事务消息分布式事务概念 什么是一致性？在分布式系统中，一致性（Consistency）是指多副本（Replications）问题中的数据一致性一致性的种类：事务一致性、数据一致性数据一致性的种类： 弱一致性：如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性 强一致性：同步复制数据，所有节点中的数据是一样的 最终一致性：就是在一段时间后，节点间的数据会最终达到一致状态，是弱一致性的一种 顺序一致性：任何一次读都能读到某个数据的最近一次写的数据 什么是XA协议？一套分布式事务标准，使用了两阶段提交来保证分布式事务的完整性XA模式中有三个重要组件：TC、TM、RM。 TC: Transaction Coordinator，事务协调者。维护全局和分支事务的状态，驱动全局事务提交或回滚。RocketMQ中Broker充当着TC。 TM：Transaction Manager，事务管理器。定义全局事务的范围：开始全局事务、提交或回滚全局事务。它实际是全局事务的发起者。RocketMQ中事务消息的Producer充当着TM。 RM：Resource Manager，资源管理器。管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。RocketMQ中事务消息的Producer及Broker均是RM。 XA模型 TM向TC发起指令，开启一个全局事务。 根据业务要求，各个RM会逐个向TC注册分支事务，然后TC会逐个向RM发出预执行指令。 各个RM在接收到指令后会在进行本地事务预执行。 RM将预执行结果Report给TC。当然，这个结果可能是成功，也可能是失败 TC在接收到各个RM的Report后会将汇总结果上报给TM，根据汇总结果TM会向TC发出确认指令 若所有结果都是成功响应，则向TC发送Global Commit指令。 只要有结果是失败响应，则向TC发送Global Rollback指令 TC在接收到指令后再次向RM发送确认指令 RocketMq中的概念 半事务消息：咱不能投送的消息，producer已经将消息发送到了broker但是事务状态没有确定，此时该消息对于consumer不可见 本地事务状态：producer回调操作执行的结果，TC会将本地事务状态发送给TM，TM根据本地事务状态确定全局事务状态 消息回查：即重新查询本地事务的执行状态，本地事务返回的结果如果是不确定，则会进行回查，重新返回本地事务状态 RocketMq中的事务消息A银行给B银行转账，分为4个步骤① A向B发送存款增加一万元的消息② A扣款一万元③ B收到消息，消费消息④ B增加存款一万元 Rocketmq只能做到步骤一和步骤二具有原子性，要想四个步骤成为一个操作，需要人工干预，见本节末。 如何保证步骤一和步骤二是一个原子操作，RocketMq的操作流程如下： Producer向Broker端发送Half Message(半事务消息)； broker给producer响应Half Message发送成功 producer收到消息发送成功的ACK，去执行本地事务（扣款操作） 本地事务执行完毕，返回本地事务状态：成功、失败、未知。broker根据本地事务状态执行commit或rollback成功(commit)：消息真正发送给consumer失败(rollback): 事务失败，消息不会发送给consumer，一段时间后清除消息未知(unknow): 状态不确定，进行消息回查，重新确认消息状态（正常的事务消息到这一步就已经结束） 如果本地事务执行超时时，broker会主动发起消息回查 producer进行消息回查，返回本地事务状态 broker根据本地事务状态执行commit或rollback 其中消息回查的结果如果还是unknow，则会继续回查，直到达到配置的最大回查次数，达到次数就报错最大回查次数、回查间隔时间等都是可以配置的 代码举例 定义事务监听器，定义本地事务和消息回查 /** * 事务监听器，本地事务和消息回查都在其中 */ class MyMqTransactionListener implements TransactionListener { /** * 本地事务 * @param message 消息 * @param args producer发送事务消息时传递的参数，用于执行本地事务时使用。不用就不传。此处的值应为123 * @return 返回本地事务状态：LocalTransactionState 有三种状态 */ @Override public LocalTransactionState executeLocalTransaction(Message message, Object args) { System.out.println(&quot;执行本地事务，A扣款操作~~~~&quot;); //返回执行成功，执行成功后broker会把消息发送给consumer //return LocalTransactionState.COMMIT_MESSAGE; //返回执行失败，失败后broker不会把消息发送给consumer //return LocalTransactionState.ROLLBACK_MESSAGE; //返回执行未知：去执行消息回查 return LocalTransactionState.UNKNOW; } /** * 消息回查 * @param messageExt 消息 * @return 返回本地事务状态，与执行本地事务的返回效果相同 */ @Override public LocalTransactionState checkLocalTransaction(MessageExt messageExt) { System.out.println(&quot;执行消息回查&quot;); return LocalTransactionState.COMMIT_MESSAGE; } } 发送消息注意：生产者的类型不再是DefaultMQProducer了、发送方法使用事务发送方法，可以使用业务参数消费者正常使用就行 /** * 发送事务消息 * @throws Exception */ @Test public void sendTransactionMsg() throws Exception { //定义事务生产者而不是默认的生产者 TransactionMQProducer producer = new TransactionMQProducer(&quot;myGroup1&quot;); producer.setNamesrvAddr(IP_PORT); //1: 定义一个线程池给producer去处理本地事务、消息回查 /** * @param corePoolSize 线程池核心线程数 * @param maximumPoolSize 线程池中最多线程数 * @param keepAliveTime 线程池中空闲线程的存活时间 * @param unit 时间单位 * @param workQueue 临时存放任务的队列，其参数就是队列的长度 * @param threadFactory 线程工厂 */ ThreadPoolExecutor executor = new ThreadPoolExecutor( 10, 50, 10L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(20), (Runnable r) -&gt; new Thread(&quot;Order Transaction Massage Thread&quot;)); producer.setExecutorService(executor); //2: 设置事务监听器，监听器中执行本地事务与消息回查，需要自己定义 producer.setTransactionListener(new MyMqTransactionListener()); //3：发送事务消息 producer.start(); Message msg = new Message(&quot;transactionTopic&quot;, &quot;test&quot;, &quot;hello&quot;.getBytes()); TransactionSendResult result = producer.sendMessageInTransaction(msg, &quot;123&quot;); System.out.println(&quot;发送结果：&quot;+result); producer.shutdown(); } 总结 RocketMq不能发送延时消息、批量消息 以上操作只保证了消息发送是原子的，那消息消费要怎么办？ 因为消费端RocketMQ有重试机制，如果不是代码问题一般重试几次就能成功，这里我们要保证消息消费的幂等性，即多次消费同一个消息对系统的状态没有影响，或者说不会影响最终正确的结果。比如上面的案例中，发生了重复消费，可能就会重复调用多次扣款的接口，我们要保证对同一个消息多次调用和一次调用的最终结果是一致的，而不是调用几次接口就扣款几次。 如果消费者一直执行失败，几乎可以断定就是代码有问题所以才引起的异常。如果多次失败并重试达到一定次数之后，可以先将该异常记录下来，通常是记录到数据库中，后续由人工处理，通过这样来让事务达到最终的一致性。 因此RocketMQ的事务消息不是强一致性的，而是保证最终一致性，并且可能需要人工介入。 目前，生产级别采用的各种分布式事务解决方案也几乎都是最终一致性的。试想一下，如果要保证强一致性的，即必须实时的保证数据的一致性，那么一定需要同步阻塞，此时将会阻塞大量的服务，降低消息分布式系统的可用性和并发度，这是更加不可容忍的。实际上也有强一致性的分布式事务方案，比如基于数据库的2PC实现，但是几乎很少使用，或者说，建议小公司谨慎使用分布式事务，能不用就不用。 与最终一致性对应的业务是，通常在客户进行操作之后，不会立即返回客户成功的信号，而是返回一个“业务正在办理中，成功了会通知你”、“钱款两小时内到账”等友好的延时提醒。 参考：https://blog.csdn.net/weixin_43767015/article/details/121308018 关于事务回查在demo中本地事务返回UNKNOW并没有触发事务回查，感觉官方并不推荐使用事务回查。且即便是本地事务返回UNKNOW也不会立即回查，而是固定的时间后再去回查，而demo中producer发送完消息就关闭了。 事务回查的触发条件，4.X版本的官方文档是这样描述的： 在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 5.X的官方文档是这样描述的： 在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 源码中也并没有对UNKNOW类型直接做处理（可能有定时器） if (localTransactionStatLocalTransactionState.COMMIT_MESSAGE) { log.info(&quot;executeLocalTransactionBranch return localTransactionState); log.info(msg.toString()); } 批量消息 概念批量发送消息需要注意的点： 批量发送的消息必须具有相同的Topic 批量发送的消息必须具有相同的刷盘策略 批量发送的消息不能是延时消息与事务消息 一批发送的消息总大小不能超过4MB字节 生产者批量发送消息不能超过4M，所以通常需要定义一个分割器确保不会超过4M，如果需要修改最大发送长度，需要在配置文件和代码中都进行设置和修改 消费者有两个属性：拉取消息的数量(pullBatchSize)、批量消费消息的数量(consumeMessageBatchMaxSize)。批量消费消息的时候是批量成功或批量失败的，一条失败则全部失败，所以要适当设置批量消费的数量。 另外，批量拉取和消费的数量并不一定和指定的数量一致，受网络影响，并不是一定会拉取到、消费到指定数量的消息 代码举例定义分割器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class MessageListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; { private final int SIZE_LIMIT = 4 * 1024 * 1024; // 存放所有要发送的消息 private final List&lt;Message&gt; messages; // 要进行批量发送消息的小集合起始索引 private int currIndex; public MessageListSplitter(List&lt;Message&gt; messages) { this.messages = messages; } @Override public boolean hasNext() { // 判断当前开始遍历的消息索引要小于消息总数 return currIndex &lt; messages.size(); } @Override public List&lt;Message&gt; next() { int nextIndex = currIndex; // 记录当前要发送的这一小批次消息列表的大小 int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) { // 获取当前遍历的消息 Message currentMsg = messages.get(nextIndex); int currentMsgSize = computeMsgSize(currentMsg); // 判断当前消息本身是否大于4M if (currentMsgSize &gt; SIZE_LIMIT) { if (nextIndex - currIndex == 0) { nextIndex++; } break; } if (currentMsgSize + totalSize &gt; SIZE_LIMIT) { break; } else { totalSize += currentMsgSize; } } // end-for // 获取当前messages列表的子集合[currIndex, nextIndex) List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); // 下次遍历的开始索引 currIndex = nextIndex; return subList; } /** * 计算单个消息的长度 * * @param message * @return */ private int computeMsgSize(Message message) { int size = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) { size += entry.getKey().length() + entry.getValue().length(); } size = size + 20; return size; }} 生产者消费者12345678910111213141516171819202122@SpringBootTestpublic class BatchMsgProducer { public static final String IP_PORT = &quot;121.4.247.245:9876&quot;; @Test public void sendBatchMessage() throws Exception { ... List&lt;Message&gt; messageList = new ArrayList&lt;&gt;(); ... MessageListSplitter splitter = new MessageListSplitter(messageList); while (splitter.hasNext()) { List&lt;Message&gt; msgs = splitter.next(); producer.send(msgs); } producer.shutdown(); }//消费者不一致的地方只有consumer.setConsumeMessageBatchMaxSize(25);consumer.setPullBatchSize(40);} 消息过滤消费者可以对消息进行过滤，有两种方式：Tag过滤、sql过滤 Tag过滤：选择订阅哪些tag，上文中订阅的都是全部，还可以这样写1consumer.subscribe(&quot;TOPIC&quot;, &quot;TAGA || TAGB || TAGC&quot;); Sql过滤：使用表达式进行更高级的过滤支持的表达式： 支持的常量类型：数值：比如：123，3.1415字符：必须用单引号包裹起来，比如：’abc’布尔：TRUE 或 FALSENULL：特殊的常量，表示空 支持的运算符有：数值比较：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=字符比较：=，&lt;&gt;，IN逻辑运算 ：AND，OR，NOTNULL判断：IS NULL 或者 IS NOT NULL 默认情况下Broker没有开启消息的SQL过滤功能，需要在Broker加载的配置文件中添加如下属性，以开启该功能： 1enablePropertyFilter = true 使用Sql过滤： 生产者添加属性1msg.putUserProperty(&quot;age&quot;, i + &quot;&quot;); 消费者过滤1consumer.subscribe(&quot;myTopic&quot;, MessageSelector.bySql(&quot;age between 0 and 6&quot;)) 消息发送重试消息发送的重试需要注意以下几点： 从发送消息的方式来讲，同步和异步会重试，单向不会。 从消息的类型来讲，普通消息有重试机制，顺序消息没有 消息发送重试机制会尽可能的保证发送成功，但可能会造成重复消费，所以消费者要做好幂等性处理 消息发送重试有三种策略可选择：同步发送失败策略、异步发送失败策略、消息刷盘失败策略 同步发送失败策略同步消息发送失败，在重试时会尽量选择其他broker发送，如果只有一个broker，也会尽量选择其他Queue。这就是失败隔离功能。 异步发送失败策略异步重试不会选择其他broker，仅在同一个broker上做重试，所以该策略无法保证消息不丢 消息刷盘失败策略消息刷盘超时（Master或Slave）或slave不可用（slave在做数据同步时向master返回状态不是SEND_OK）时，默认是不会将消息尝试发送到其他Broker的。不过，对于重要消息可以通过在Broker的配置文件设置retryAnotherBrokerWhenNotStoreOK属性为true来开启。 消息消费重试 对于顺序消息，当Consumer消费消息失败后，为了保证消息的顺序性，其会自动不断地进行消息重试，直到消费成功。消费重试默认间隔时间为1000毫秒。重试期间应用会出现消息消费被阻塞的情况 对于无序消息（普通消息、延时消息、事务消息），当Consumer消费消息失败时，可以通过设置返回状态达到消息重试的效果。不过需要注意，无序消息的重试只对集群消费方式生效，广播消费方式不提供失败重试特性。即对于广播消费，消费失败后，失败消息不再重试，继续消费后续消息。 对于 无序消息集群消费 下的重试消费，每条消息默认最多重试16次，但每次重试的间隔时间是不同的，会逐渐变长 重试队列：对于需要重试消费的消息，并不是Consumer在等待了指定时长后再次去拉取原来的消息进行消费，而是将这些需要重试消费的消息放入到了一个特殊Topic的队列中，而后进行再次消费的。这个特殊的队列就是重试队列 死信队列当一条消息初次消费失败，消息队列会自动进行消费重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。这个队列就是死信队列（Dead-Letter Queue，DLQ），而其中的消息则称为死信消息（Dead-Letter Message，DLM） 死信队列的特征 死信队列中的消息不会再被消费者正常消费，即DLQ对于消费者是不可见的 死信存储有效期与正常消息相同，均为 3 天（commitlog文件的过期时间），3 天后会被自动删除 死信队列就是一个特殊的Topic，名称为 %DLQ%consumerGroup@consumerGroup ，即每个消费者组都有一个死信队列 如果一个消费者组未产生死信消息，则不会为其创建相应的死信队列","link":"/2022/11/13/RocketMq%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"运维","slug":"运维","link":"/tags/%E8%BF%90%E7%BB%B4/"},{"name":"RocketMq","slug":"RocketMq","link":"/tags/RocketMq/"},{"name":"消息中间件","slug":"消息中间件","link":"/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"消息队列","link":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"categories":[{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"消息中间件","slug":"消息中间件","link":"/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"pages":[]}